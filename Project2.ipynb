{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><center>Project 2<BR><BR>\n",
    "Perceptrons</center></H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 1: Identifying fake news\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Read <a href=\"https://www.technologyreview.com/s/609717/can-ai-win-the-war-against-fake-news/\">this article</a> about how machine learning is being used to detect fake news stories.</P>\n",
    "\n",
    "<P>Please address (minimum 200 words) the following questions in the space below. What is your definition of \"fake news\"? When might two different groups of people read the same story with one group understanding it to be \"real\" and one group understanding it to be \"fake\"? What are some different ways that fake news might be combatted?</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fake news is news that intentionally spreads misinformation, information that is not accurate or misleading. Two people might read the same story and one might consider it to be real while the other understands it to be fake, and this all depends on their perception of the news which is usually tied to their political stance. Examples of this include someone who is far-right reading a website that promotes far-right ideologies and considering it \"real\" while someone who is left-leaning might read that same website and consider it to be \"fake\". \n",
    "\n",
    "\n",
    "Fake news can be combatted using machine learning algoirthms. Such algoirthms can be trained to detect fake news by looking at some features such as  headlines not matching the body, or too many capital letters in a headline, and cross-checking stories with ann official database of thousands of legitimate and fake stories. Some other ways to combat fake news is by allowing users to be able to report when they consider news they read online to be fake, and this data could be used to build other databases for machine learning. Allowing real humans to be able to flag might allow for algoirthms to account for political or general human biases. Another way is to follow EU laws on transparency and make sure that each posted article has verified sources from a pre-determined database of legitimate sources. One final way is to make sure that fake news is not spread as much is by making sure there is a vetting process when releasing important articles, such as news organization cross checking with other news organizations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 2: Using Perceptrons to predict survivors of the Titanic\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>This from <a href=\"https://www.kaggle.com/c/titanic\">Kaggle</a>:\n",
    "\n",
    "<blockquote>\n",
    "<P>The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.</P>\n",
    "\n",
    "<P>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.</P>\n",
    "</blockquote>\n",
    "\n",
    "<P>Together with the downloaded file containing this notebook, you should find a csv file named <code>titanic.csv</code> containing information about passengers on the Titanic and whether the passenger survived the tragedy. The first row of the file contains header information and each subsequent row contains information about a passenger. There are nine columns of feature values, and the tenth column contains labels, -1 or 1, indicating whether the passenger did not survive or did survive, respectively. The features in order of how they appear in the file are:</P>\n",
    "\n",
    "<ol>\n",
    "<li>Ticket class, 1=First, 2=Second, 3=Third</li>\n",
    "<li>Sex, 0=male, 1=female</li>\n",
    "<li>Age in years</li>\n",
    "<li>Number of siblings and spouses aboard the Titanic</li>\n",
    "<li>Number of parents and children aboard the Titanic</li>\n",
    "<li>Passenger fare in dollars</li>\n",
    "<li>Whether the passenger's port of embarkation was Cherbourg</li>\n",
    "<li>Whether the passenger's port of embarkation was Queenstown</li>\n",
    "<li>Whether the passenger's port of embarkation was Southampton</li>\n",
    "</ol>\n",
    "<P>In this task, you will use the <code>sklearn</code> perceptron algorithm to predict whether a passenger survived the Titanic.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code in the space below to read in the <code>titanic.csv</code> file and store the feature vectors in an array <code>X</code> and the labels in an array <code>y</code>.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "# Read in data and store feature vectors in array X and labels in array y\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load(csv_file):\n",
    "    \"\"\"given a CSV file where each row is a data point,\n",
    "    with the last column being the label and the rest being the training.\n",
    "    \"\"\"\n",
    "    DATA = np.loadtxt(csv_file, delimiter=',', skiprows=1)  # Read data from comma delimited file\n",
    "    X = DATA[:, :-1]\n",
    "    y = DATA[:, -1] # get the last column of the rows (should be 0 or 1)\n",
    "    return X,y\n",
    "titanic = load('titanic.csv')\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code in the space below to split the data into <em>training</em> and <em>testing</em> data. Use 80% of the data for <em>training</em> and 20% of the data for <em>testing</em>. You may use the <code>train_test_split</code> function from <code>sklearn</code> here. Set <code>random_state=0</code> for consistent results.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Class</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th># of siblings and spouses aboard</th>\n",
       "      <th># of parents and children aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked Cherbourg?</th>\n",
       "      <th>Embarked Queenstown?</th>\n",
       "      <th>Embarked Southampton?</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticket Class  Sex   Age  # of siblings and spouses aboard  \\\n",
       "0               3    0  22.0                                 1   \n",
       "1               1    1  38.0                                 1   \n",
       "2               3    1  26.0                                 0   \n",
       "3               1    1  35.0                                 1   \n",
       "4               3    0  35.0                                 0   \n",
       "..            ...  ...   ...                               ...   \n",
       "886             2    0  27.0                                 0   \n",
       "887             1    1  19.0                                 0   \n",
       "888             3    1  30.0                                 1   \n",
       "889             1    0  26.0                                 0   \n",
       "890             3    0  32.0                                 0   \n",
       "\n",
       "     # of parents and children aboard     Fare  Embarked Cherbourg?  \\\n",
       "0                                   0   7.2500                    0   \n",
       "1                                   0  71.2833                    1   \n",
       "2                                   0   7.9250                    0   \n",
       "3                                   0  53.1000                    0   \n",
       "4                                   0   8.0500                    0   \n",
       "..                                ...      ...                  ...   \n",
       "886                                 0  13.0000                    0   \n",
       "887                                 0  30.0000                    0   \n",
       "888                                 2  23.4500                    0   \n",
       "889                                 0  30.0000                    1   \n",
       "890                                 0   7.7500                    0   \n",
       "\n",
       "     Embarked Queenstown?  Embarked Southampton?  Survived  \n",
       "0                       0                      1        -1  \n",
       "1                       0                      0         1  \n",
       "2                       0                      1         1  \n",
       "3                       0                      1         1  \n",
       "4                       0                      1        -1  \n",
       "..                    ...                    ...       ...  \n",
       "886                     0                      1        -1  \n",
       "887                     0                      1         1  \n",
       "888                     0                      1        -1  \n",
       "889                     0                      0         1  \n",
       "890                     1                      0        -1  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('titanic.csv')  \n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count First class :  216\n",
      "Count Second class :  184\n",
      "Count Third class :  491\n"
     ]
    }
   ],
   "source": [
    "count = (titanic['Ticket Class'] == 1).sum()\n",
    "print('Count First class : ', count)\n",
    "count = (titanic['Ticket Class'] == 2).sum()\n",
    "print('Count Second class : ', count)\n",
    "count = (titanic['Ticket Class'] == 3).sum()\n",
    "print('Count Third class : ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of men in Column Sex :  577\n",
      "Count of women in Column Sex :  314\n",
      "Count of children in Age Column :  139\n",
      "Count of girl children:  14\n",
      "Count of boy children:  14\n"
     ]
    }
   ],
   "source": [
    "count = (titanic['Sex'] == 0).sum()\n",
    "print('Count of men in Column Sex : ', count)\n",
    "count = (titanic['Sex'] == 1).sum()\n",
    "print('Count of women in Column Sex : ', count)\n",
    "count = (titanic['Age'] <= 18).sum()\n",
    "print('Count of children in Age Column : ', count)\n",
    "count = (titanic['Age'] <= 18 | (titanic.Sex ==1)).sum()\n",
    "print('Count of girl children: ', count)\n",
    "count = (titanic['Age'] <= 18 | (titanic.Sex ==0)).sum()\n",
    "print('Count of boy children: ', count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code in the space below that uses <code>sklearn</code> to create a Perceptron, setting the number of epochs to be 20 and the random_state to be 0. Train the perceptron on the <em>training</em> data. Once trained, report the accuracy of the perceptron first on classifying the <em>training</em> data and second on classifying the <em>testing</em> data. Finally, print out the weights for the 9 features, as learned by the Perceptron.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -52.      758.      -16.74   -470.      -83.       30.1803   47.\n",
      "    78.      -74.    ]]\n",
      "0.8212290502793296\n",
      "0.7696629213483146\n"
     ]
    }
   ],
   "source": [
    "# Create sklearn Perceptron with 20 epochs.\n",
    "# Train perceptron and report its classification accuracy on both training data and testing data.\n",
    "# Output weights of 9 features as learned by the Perceptron.\n",
    "from sklearn import linear_model\n",
    "\n",
    "perceptrons = linear_model.Perceptron(max_iter=20, random_state = 0)\n",
    "perceptrons.fit(X_train, y_train)\n",
    "\n",
    "weights = perceptrons.coef_\n",
    "print(weights)\n",
    "\n",
    "\n",
    "test_score = perceptrons.score(X_test, y_test)\n",
    "train_score = perceptrons.score(X_train, y_train)\n",
    "print(test_score)\n",
    "print(train_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Please answer the following questions.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Are the feature vectors linearly separable? How do you know?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, because they are all binary features and not continous, therefore we can seperate them using aperceptron algorithm which completes binary classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Based on the 9 feature weights, what feature contributes most toward predicting survival?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex (because it has the highest weight of 758)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Were younger or older passengers more likely to survive?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Younger passangers were more likely to survive because the sign is negative. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Were passengers that paid a higher fare more likely to survive?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes because the fare factor is positive, which means the higher the fare the more likelihood of survival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Passengers were most likely to survive if they embarked from which of the three ports?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cherbourg, as it has the highest positive number. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 3: Implementing your own Perceptron\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>In this task, you will implement your own perceptron learning algorithm. You may use the <code>numpy</code> and <code>matplotlib</code> libraries, but <font color=\"red\">you should <em>not</em> use any part of the <code>sklearn</code> library</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The file <code>dataset.csv</code> contains 500 examples labeled either as -1 or 1. The examples have 2-dimensional feature vectors, i.e., two features each. The file contains a header line. Write code below to read in the file and store the feature vectors in an array <code>X</code> and the labels in an array <code>y</code>. In order to visualize the data (since it is two-dimensional), you should also plot the data as a scatter plot using the <code>matplotlib</code> function <code>scatter</code>. When plotting the data with the <code>scatter</code> function, you can set the color of points based on their labels (-1 or 1) in the <code>y</code> array by providing the argument \"<code>c=y</code>\".</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2df4xc1ZXnv6fKhV1tMm6j9Cq4oTHKRmaGGLuXTmItq92BzWAUB9IDIQ4Du6OdP9BIO9rgZXtjJii2s0Q4as3Aamb/GDSJdlYhjM2P7QDOyCTC2dkwMkk73Q7xYK9CwECBNp61mwx0Gaqrz/5R/cqvXt17333v3VfvvarzkZDodvV7p96Pc889P4mZIQiCIBSXUtYCCIIgCMkQRS4IglBwRJELgiAUHFHkgiAIBUcUuSAIQsFZlcVJP/zhD/PGjRuzOLUgCEJhOXbs2D8w80jw95ko8o0bN2J2djaLUwuCIBQWIjqt+r24VgRBEAqOM0VORGUimiOiZ10dUxAEQQjHpUX+JQAvOzyeIAiCYIETRU5ElwHYAeAvXRxPEARBsMeVRf4wgP8MYFn3ASK6m4hmiWj2zJkzjk4rCIIgJFbkRPRZAL9i5mOmzzHzI8w8wcwTIyNd2TOCIAhCTFykH14H4BYi+gyANQB+g4i+zcx3OTi2IPQtM3M1TB8+hbcW6tgwXMXU9k2YHB/NWiyhgCS2yJn5Pma+jJk3AvgigOdFiQuCmZm5Gu576iXUFupgALWFOu576iXMzNWyFk0oIJJHLggZMH34FOqNZsfv6o0mpg+fykgiocg4rexk5h8C+KHLYwpCP/LWQj3S7wXBhFjkgpABG4arkX4vCCZEkQtCBkxt34Rqpdzxu2qljKntmzKSSCgymTTNEoRBx8tOkawVwQWiyAUhIybHR0VxC04Q14ogCELBEUUuCIJQcESRC4IgFBxR5IIgCAVHFLkgCELBEUUuCIJQcESRC4IgFBxR5IIgCAVHFLkgCELBEUUuCIJQcESRC4IgFBxR5IIgCAVHFLkgCELBEUUuCIJQcESRC4IgFBxR5IIgCAVHFLkgCELBSazIiWgNEf2YiI4T0Qki2udCMEEQBMEOF6Pe3gdwAzO/S0QVAD8ior9h5qMOji0IgiCEkFiRMzMDeHflx8rKf5z0uIIgCIIdTnzkRFQmonkAvwLwfWZ+UfGZu4lolohmz5w54+K0giAIAhwpcmZuMvNWAJcB+CQRfVzxmUeYeYKZJ0ZGRlycVhAEQYDjrBVmXgDwQwA3uTyuIAiCoMdF1soIEQ2v/H8VwKcBnEx6XEEQBMEOF1krlwL4KyIqo7UwHGTmZx0cVxAEQbDARdbKzwCMO5BFEFJjZq6G6cOn8NZCHRuGq5javgmT46NZiyUITnBhkQtCrpmZq+G+p15CvdEEANQW6rjvqZcAQJS50BeIIhdSJ2trePrwqbYS96g3mpg+fEoUudAXiCIXUiUP1vBbC/VIvxeEoiFNs4RUMVnDvWLDcDXS7wWhaIgiF1IlD9bw1PZNqFbKHb+rVsqY2r6pZzIIQpqIIhdSJQ/W8OT4KB68dTNGh6sgAKPDVTx462bxjwt9g/jIhVSZ2r6pw0cOZGMNT46PiuIW+hZR5EKqeMpzUHK4s87QEQYTUeRC6gyKNZyHDB1hMBEfuSA4Ig8ZOsJgIopcEByRhwwdYTARRS4IjshDho4wmIgiFwRHuMpXn5mr4br9z+PK3Ydw3f7nMTNXcymm0IdIsFMQHOEiQ0cCpkIcRJELgkPiZuh4aYs1hT9dGnwJYYgiF4SMCVrhKiRgKpgQH7kgZIwqbTHIumqlR9IIRUQsciEzpAqyhY21TdQDQYTCIopcyIReBPWyWCjinHPDcFXpG/ezsNhwKabQZ4hrRciEtKsgvYWitlAH48JCkWYqX9xzqtIWg0guumAisSInosuJ6AgRvUxEJ4joSy4EE/qbtKsgsyiXj3tOf5tdAAh6UQjA9VeNOJRU6DdcWORLAO5l5t8EsA3Avyei33JwXKGPSbsKMoty+STnnBwfxQu7b8Br+3fgzm1jHcqcATx5rCaFQYKWxIqcmd9m5p+u/P8/AngZwOBFrIRIpD21J4tyeVfnPHLyDDjwO2m+JZhwGuwkoo0AxgG8qPi3uwHcDQBjY2MuTysUkLT7lGcx0MLVOW0se1VQFRicvu9CJ8QcXPtjHojoYgD/C8DXmfkp02cnJiZ4dnbWyXmF/sevtNZVKyBqZXGEKauss1aGhypgBt6pNyLJfd3+55VZLKPDVbyw+wZlAVGlRAABjeaF97laKctIuz6DiI4x80TX710ociKqAHgWwGFm/tOwz4siLwZ5yPMOq3rMq7JKIrfqbwnAndvG8MDkZq2iV+Epf6E/0CnyxK4VIiIA3wTwso0SF4pB1s2bTL1H/OS1D0lYtaZJ7snxUcyePotHj77e9pV7Ac+JKy6JFLDtRWl/Hhb8QceFj/w6AP8GwEtENL/yuz9m5u85OLaQEbpUunsPHgfQqcxdv8g2vUf85LEPiY1Mps+YAp42BUQeaeef92thV9FwkbXyI2YmZr6Gmbeu/CdKvODolEyTuaPIJY3CG5veI37yWCxjI5PpM6aApyrjp1IiVMqdGehpB3eB/izsKiJS2ZkT8jZMwKRk/C9qGi9yFAu7F8oqDmHVmmFym1IZ/QVEhJYffPr2LZj+/JaO3/UidtCPhV1FRHqt5ICs/dEqVKl0frwXNY0XOcx1UCKAGcZttovteJJjBNMro2StAOGpjLq+571+XnT3qsiFXUVEFHkOMFkdWSly77z3HjyOpiKzyXtR03iRTYuITZaKi4XRxTHiDpnwnyPvvuG08/XTXij6BVHkOSCvVoenNEwvahovsl+J1RbqKBOhyYxRS2XmYmGMeow0AnJJFoJe0Y+FXUVEFHkOyLPVEfai2r7IURWdjRLTHTPpwjgzV9O6dlTHyKNrrJekueAUZWeSNaLIc4Brq8O1dRj2oob9exqKznTMJAujd1wdqmOEBeR090J3nyTdrpMi7EyyRhR5DkhqdQRL2N/7YKldqp0H6zCNGIDpmEkWRlPqo+4YOku/tlDHrgPz7Xxw/70AoFyIZk+fxZPHagNr3QvxEEWeE5JMX/crhIV69yQZF4HTJFZiGjEAk/IEgAdv3RxLXpNM/2xsnfIYpiwbUxdD1ULkr+YM/o0ockGH5JEXHNvimSRKM2lRhuuWsjNzNZQMQyw9C/aF3Tfg1f078MLuG6yVoEmmv3vlrPI720z48fPWQl17P3Sdj7IOfAv5RhR5wbF9wZMETpMWZbjsPe4tKqqUyDiyBTHJxIDyuMEJP2FsGK5Gvh95CHx75K14TRDXSuGx6bsRVJpR3SRJXSMuMw/S3oFMjo9i3zMncE4z7Fh3XM81FtaZ0H8v7jkwr/2cn0qJtPcvaqFRUtIKXEtwNxmiyAtOWAUmAbjt2tGOTImoL6KL9EhXmQe92IHsufnqjiBl2HGDirVSpo6+4ISWNR/MgzctGH78uw9TTKQXgVHXgetBT910hbhWCk7Ytp7R6qTnEcdNkvZYtijYKGgXBUnBuZmAeghyMH6wUG8ADKwfqrR7njy0cyteU/jq99x8tZVvfZmBvU+fAGDXHveeA/OpuTxcB66ll4obxCLvAzxr98rdh5RWpP8l0237Te6APBVlqHYglRLh4jWrYrsXVFv7ByY3A4C2J7j/mgQVUWOZMXTRKsx99UbjeVXXVXcfPMvbVmGmZdm6Ll7La1Vz0RBF3kfYvGReuXuQsiELBMhPUYbrRcW0tTf1BPfO5yJ+4Jd94+5Dxs9H6UWeRtqi6+K1PFc1FwlR5H2EzUumy/YwZYFkiS4Q5ko56bb2pkCkX0m7VkTrhypKv/n6oQqA8JiISlaXwUTXC6n0UnGDKPI+wuYlG9UonjIRZuZqiXukuKQXgbA4W3i/knaliLzrrFLilTJhz81XA9C3x9UFTddVK86vocuFNE9uuyLjZPhyVGT4cnaYxqgFW8SqPtvLYcdh0+TTPIcO1fdPutiZ7oltx0fdvVpTKSmVfB6GMg9S2qGr75ra8OV+ph8fNFOf8aBPNes+6Tb+56T3aGr7Jkw9fhyNZTuDZvWq7kSvpBbq3qdPKJU4rchnc2ydZbtL4yLKOpg4SGmHvfiuosg19PODNjk+avWCRwnkqRQqkGzLrPM/Dw9VlJZ0baGOqSe6h0ObCCsACrJQb2DXgXnMnj7bzmxJspjMzNWU/XGAC5WkUb5L8LNeT/cgwys+96yIayQU0bjqhUHkJI+ciL5FRL8iop+7OF4e6Pf8Vpv+J7Y9UlS9WKaeOI6px48nGpqrHDJcJrx7fknrDmk0GfueOWF9DqBVFRkFRistcWaulrgPTdjzlNRyntq+qWsoMwC8e34p1dL6sDL+ONk+RR3E3IsUS1cFQf8dwE2OjpUL+j2/1abIx7YQSJlL3eQud0XUhdBf7OQV16y9aFWoG8TWuvaIk2HCaFVm6hb8/3hwHlv3PRfajyTseSqtBKHjMjk+irUXdW+8G8ucmlFio3DjNFIrqnHlummcCieKnJn/FsBZF8fKC724+FmiUpLBIJ7NZ4Boi1vUhXByfLSji+E7GjdEEqa2b+qq4rTh3GJDuzNY5pYbJsxyDHuemsyJrE6T6yaOUWLTMMtG4capFi6qcdWLyuielegT0d1ENEtEs2fOnAn/g4zJU1l6WgSVpMpf533moZ1bAQC7FOXfURa3pAuhzd8PV6P5fyfHR7XtYwEYlXxYIZWHznK0aYEb1+qMM+1Id5zr9j+PjbsPYdeB+VDXho3CtTUSbOTNu3EV57tGpWfBTmZ+BMAjQCv9sFfnjYvkt17g/pmXOkrVg4FfZdl8mQBGhxvExUIYVhBTArD3lqtDjxMMmhEBqkzcMhHu+NTl+PbR15XHaTKjWilH7sgYbLS1plLCwmLDaT/yONOOggSD/qpK13sPdgaYTUFqP1GzfYpcPJR2ZbRkrRjIS1l6lszM1UKn1ugWPdXv4oyv2zBcxfVXjeDIyTMdiu/cYgMlarkxgJYlvveWqyPnXJvyyJvMeGByM549/rbSReHleeu6JfrxLEdVB8NqpYyHdm7VZpnEsTpNyt/WIrRpG9xk7sgWmtq+CVNPHO/oAAlcCLDmpaq0nxBFHkIR051cMn34lJWVqFv0XLU29VvEnuJ7eOfWVHuaA2h3ldx7y9Vaa9AmhdFvObqYN2rzXOos49HhqvV1s90JeNlC3nOw9+kTXQufF2BN8v6IcaXGiSInoscA/DaADxPRmwD2MPM3XRw7S/oplzzugmR6kcOsxLjntFG0SfJwbZWTX4GGWYMmJe7fKczM1bQ7gLcW6lZWp+1zaVoUbO9NlCZd5xYbuHL3IWwYrjoNsArhuMpauYOZL2XmCjNf1g9KHChuulOQqPm3M3M1jH/tOWzUtMUFLlQdujqnnyitWuOgW4CGq5VYAamw77R29aq2Eg8LPtooWNvnUhdkmz191ipoCUSfR+odTxcCzntgsqiIa8VAUdOdgkSpLJuZqyn9m0H88ytVxzC1APBk0ikrWyuQVs5l4xP3fM9+n7qfaqVs9K+rrOBdB+bx+OzrOPrLc8bze89LWPDx+qtGrCztKM9l0BVhE/MI/r0nu3e/zr33PhYby4Zv3Ho+vMlI/u9YhMBkERFFbqBfeiVHefGnD58KVeIeKkUTNhzZ+xudspqZq+G995eszm9Twh5UwColvn6ogj03t5T4/TMv4bEX30CTuZ2x8sDkZqUSZgAvvBJePuE9L2HBR9sFN8lzaRvz8KNaDGz603jj7QY1vtRLRJEbKHK6k58oL37U3Ua90WwHuQB7/3bwZ89SV6UW6np028hrI8/QRavaStwfVG0yt3+OuwvzxsNdt/95rQL1go+2Da6uv2qky6omtBbFrfueMw5jjhPzULl7pm/f0v5dSTOsRNdh0UW3yEFOQFAhitxAv6Q7qRYk1fxJIFpwy+PcYgP3z7yEIyfPxPZbv7VQ1yrdX9eXtMo8zAq1UcDeZ77zojpX/LEX34h1XQDgn3/0Ehz48Rta69VvGAxrvuPwUKXDPRR0WcD3c9gwZt330MU8dIHVB2/d3FbSuha6UY7nl9FEPyUguESGL4dgU/2YdybHR3HbtaMdAShv/qQ/wBXFrRHk0aOvx1biQEvB6JRukxnvLDa6mj/Z7I5s3A0MYOu+55RuF+/8qkXPxHC1gru2jeHvXjmrVeLBgKpuNMD7jWY7cOzJa4tNaTwBuHPbmPLZtgmsRqlcTJpA0C8JCK4Ri7xPCW4/Fz9YMga4TMMNbIiiXHRBMF0xDAAsA1hdIvyTD62JtDuyHY2mS5cDWtWdR07atZXwBk8ALTeR6boE3Q66PjJhgcUwgvn+gP0u0xRfiePiSJpA0C8JCK4RRd6HRKlcDMuoUG3jk+AdzxsCHZyAY1K69cZy5Kk2fsVlylox0WQ2XkPvmP7vct3+50MXj6Ai1LlWkhLclUQpqjGV28dxcSRNIOiXBATXiGulD4lSuRiWUeFlHnhb5ru2jSm35rZ4OrTJ3A7Q3XvwODbuPoTpw6dw27XuXVeee+y1/Tvwywd34LX9O2J1O9SxzJ1VnkC4hbj2onJXnv2755eU7qOoTcD8VEqExQ+WQtvp6tA1j2M2B62jHM97DmzkG4RmdnEQi7wPiVO5aCrnDlrBE1dc0tUH5bEfv4FmRFPXr9SB1sv85LEahiolpTthfcSpNqatf9zgpY5gmuC6akXrrikRUCmXlCXsQOdu5fqrRnDoZ29byzG8Mox5YbGBddUK3vtgqW3lxwkM6lwxUUbIBe/DbdeOtgPj/h2fjXz9koDgGlHkfYh2O1ytYO3qVcoXIEqqpWpr/qimO2BU6o0m1g9V0Fjmjnx2/yR5G8KyG3SNnZLgV2Km7rblEhl98l5HxeuvGsGBn7wRScb5PTd2ZLgEidPaIMoIOd30qGDfnPVDFQwrFjsb+aTfSjeiyPsQnVI2VS7GsXRm5mrK5khJWVhstDsBxrW6TJN77tFYk0nxt2k1jY9rNLltdeuoN5r4zouvR/bn2wStXQQGbRd+nZvPFAsY9MBlHESR9yFxt59RLB3b6r44bFgpkElidemUQRJxSwDKZdJayOcWG9i4+xDKRKEBYpMS94gqKwFWi5SLwKDtMxZHKQ964DIOosj7lLS3n9OHT0VW4iUA61YyM3TZMK4CV6594EBLie/8xOWhhU82SjoNbM7qMjBo84xFvQ8SuIyHZK0IsYhqaRGA39s2hrmv3ojX9u/AQzu3tnt9e+PSXI7Aitq1z4ZGk3Hk5Bm8sPsGp1kvOiqO307/9bWZvemCsPuwfihex0mhE7HIhViYLC2V/5eBjqKa4Nbcy9CYPnwKuw7MW7uDdJkpk+OjmD19tt0AyxXeAhbV0vSaR0WR5OI1Fbx7fqlj5+PtarxeKu+9vxQaowjufnpZ5u4dTxVLqVbK7WZlQjKIM9gGTkxM8OzsbM/PWxRcNwXSdfRLIoPOR14x+JAJwKv7d7T/3qbi0t+ZUCWjqofMndvGMHHFJYkqVXV46ZjBBlsmykR45cHPYGauhl0H57Wl+CoeDgn6btx9yPj3qira1au6Ux+BzlRT3f2P+2wGA+Om+yroIaJjzDwR/L1Y5DnDtbVk6uinU+Y2MqgsLe/lNKWmmVLjVJxbbGi/v6617KNHX8ezx992rsS9lMDr9j8fyRpvMrevaRQl7rlvXth9Q/u67Tow3x4J531GdUiCuglXvdHUXhdvt6G7/7Onz+LJY7XIz6ZqwT3vqxOQbobJEYs8Z+iUhK4laBgfve97SteCZyWmIYOuG95t1452KIIoqM59pWGCkQnbqffdf1fCUiC/3QYvFhAn+OqV/auupzeAWsVd28aUAyTCzvXC7hu091+XMrl+qIKhi9T1CYD5edJ9t7R85UVfNHQWuQQ7c4brpkA6/7DJb5xUBl03vCMnz8S2klXnHo5Y6YkVWYKdIG2pN5ZDlXjwuF4WRtz7p2vvW280jbnYD0xu1qbxrR+qGMvcTV0oVZxbbBjHxpmep152M0wyfjDviCLPGbqXL25urUlh6bIVXMigav+bpNBDVTH47nl9y10iaJXVkZNntO6IJFRKhDu3jSmzMOLevzhplN4OQNeXZM/NV+PBWzd3tDxYveqCKtDJWjaVq/oIKmLT89TLboamRaNXWTxpIYo8Z7hsCjQzV0OppH/5dBZJWo2J4iozXcWgKY+dGcpdARB/aHMYjWXGs8ffxtT2TV3968PS8ColUjbMuv6qkUgLjP9ahfUJ9/upF+qN9rOgOme1UsYdn7rcOqXTr4hNz5PumSgROVequsXBew+KbKk7CXYS0U0A/iuAMoC/ZOb9Lo47iLhsCjR9+FRoIytVb4u0GhPp/KEq37kXxAu2ufUIs9i88WnBTJuwKfZAMkXvKUQAxms6PFQBc6sHuXd9/f/eHqlmmLEZpEzU5VvWFe3se+aE0jrd98wJnG8sd42Ru+3aUTwwuRkTV1yiHKwdxK+gw54nVXaRv5Gaq9RI3e6mTGQ9nDyvJFbkRFQG8N8A/A6ANwH8hIieZua/T3rsrMg6IKJ6+Wxl8n/OVgHYTF+Pi67zXfB7BDsqhl1zk8tBt3uwmWJv02kwrKd5vdHEvQePA7gwUNr/3R7auTW0503U7B4AWGbWHtcvg6nvuer3/hoA02xRD9X11z1PQSWvmv/pSqnqDImwLJ4i4MIi/ySAXzDzLwGAiP4awOcAFFKRZzkT0JS7ayNT3Ck/afW20HW+G65WupRZ1IVDN/ln/VAFO665VFlYZHoxo2TU8MoQibAy/aknjitT9qaeOI69T5/osMbTvI/B48UZXuG/dmHFYLddG+1e+u/9lZq8eBdKVbczsO3kmGdcKPJRAG/4fn4TwKeCHyKiuwHcDQBjY2MOTpsOpoBImorcpKxtZYoyUMIjzd4WOnl07oco6F5KANrraOq5HiWjxjtXmLJtNFnZwbDR5HbuvWpR3vt0t9vDT6VMAKMjRmC6j1GeC1VrWaBTqZm+e5MZTx6rYeKKS2Ld27QnAKkMhtnTZ7tSNYvW88VFsFMVi+naeDLzI8w8wcwTIyPRBtn2kqxmApqUta1MJhn9E37S6m0RjPybLFYXKWaqzBjTdTQF3aLcX29Atc00I5u+Yp5vGmhdQ1PJ/ehwFdOf34Lp27do72OU++BnuFrB3luuDg10+4Oouu8T9972egLQzFwNTx6rKWMCRfGPA24s8jcBXO77+TIAbzk4biZkNRPQpKxtZYoy5cc1UeaEeiRdHFWuKNN1NAXdovijF+oNTD1+HEsOW/ieW2y0v48O1X30vsv04VOYPX0Wh372dofrJDiFR0ewX31YvMKzbHVFWXHvba8nAOmqg22HbecFF4r8JwA+RkRXAqgB+CKA33Nw3EyIMinHJSZlbStTVrID8dw6SRZHnStKF8hbV63guv3PKwOOM3O1tpVtSxp92MN6ifvvoy7+oEIlaaVMWHvRKqWfPixe4V9AVcFJINm97eUEoKx24K5JrMiZeYmI/gjAYbTSD7/FzCcSS5YRvbYIPExKOIqVlIXsQPQHP+kCo3OhrF5V6spEqJQI732w1OGX3nVgHrOnz2qba629qIxlZtQVs0OTsN6QMRL2d0njIcPVijbAaktwAVEp8UqZ8N77rYHPeS+Dz2oH7hrptZIjsk57TEIUX6wuN1yH6rrsOjCvdResD+RoL/oGEPvRNZZKC6+/zdZ9z0Uaj6fqPRKnz4wLF5upD8syM4aHulvvptk7JSm6vkB5lVd6rRQAVfCuKExt3xRagVgpER7euTXSd9P1xzD1WTm32MD7S8t4aOVcOkXNiJeKZ6JiqKT1rFdVQFGHV6zilZF7xLEYXbgL9CP0GK/u34Ghi1Z1uZ3S6p3igrDq16IgbWwLRh6sdp0MqjQuPxevWRVZ1igulOBn7j14PLR4xSVe1ocucOplefhdYGG7GF2F49T2TZFnprpwF4S5IvLgc476jvTSJ58WYpEXiDx0bzPJ8MDkZjy0c6v2b02T5XXoFMA79QYevHWzsZFTkznU/ZCkUVaZqG3FPbxzK+b33NhWssG+KQCw+MFS+155u6+7ttnXVPgt28nxUVy8Rm+H6bowJiUsPdB107eo5OEdyQJR5AUiactPU4c32+5vYTJMjo9q84vjvMzrqmoXyrpqK/i3nDDGk+SvmyvuBJWrqKlod3tusYFdB+Zx/0zLsvZymKPgX9h0CyMB7ZmoYe6CqF3/wlwRvc4DD9LLtrh5QlwrBSLJttVUOQroqyFtm1UFu925SoPUGdxEK90dNelvvUBnze99+gR0uS7eBCOvt0zUzBP/wmZyc9i4C+K2ozAdO+g28vv4w47rgjy4drJAFHmBSJIqpbNU7j14HB9as8q6LYGNDK7SIO+fecnY3Om+p15KRYlXSoSL16xqDzjW+bEZaFuw/u8alpHCvs9Hxb+wmRZMGz+xrgNi0nYUqq6GvepZ1C/phFERRZ4xUQIzSSxd09QXneJR/Y2tDEkDSGHDjVWtRz0qJSBJ+vf07Vs6ZDelC+59+gTeX1qOVNHqfU7X18SE350SXDDXVSsgahUW+as5awt13HNgHnufPtGu3pyZq2kXybAFRvXMAq2FwTumqpq0Fz2Lor4jeUgecIEo8gyJurUNs3RND2WcSTMqKyaKtZ3kJXnsxTeM/26yxNeuruC99ztzmUuA1t3hx/Pv+6tAP1jSuz+iKmI/732whEqJujJPvDx41bGDMQNvwQw+S6qrs1BvtAuhTCXoJutV9cxOPX4cy0BH73vd3UnbxRH1+cyq06lrpCAoQ1wOWg4rbLh/5qVIw3iTFkUkLbTYqGlnaoMX7Au+zGEl8EkHRMeSlVptcYGWAt9z8wWLWZVeWCkTpj+/pesaRinICuu9oqoAjdMfXUUv+v7Y4nrQeS/QFQSJRZ4hLgMzYdH6YIe3IGGT0F3KY3Nc3cR2G3TBPpMi8ueA90qJAxeUONA5em1yfLTDVeHRaLLyGkZ5Zhjm6xtssRvsqR6XvLWG7afAqCjyDHEZmIk6qdyPN5DX5XYy6UtyxxlJEpkAABJaSURBVKcuN/rIdZiUhcp/SgDu3DaGByZb8zx7WUAUJLjQ6dILvWto07xKR5O5q6BK59d+7MU3Yi+qXul+Hv3P/RQYlTzyDHGZcxtnUjkQb6JLUnlseGByc8dkdxtMfaQ9pVdvNNtFRKMrXRA9JR5FvrQITuJRsWG42lX4ElXResFi/7XQHSHs2JUSoaxoTVApEf7kC1uctJxIY8p91jnvLhFFniEu+zzEmVQOtF7Sbx99HVv3PYeZuZqzF8bFS/KN265RVkjq0PWR9is94II1qrIQw6bdp01wEo/uGiZ1AXnK2X8t1mv615iqZ0eHq5i+fQv+5PYtHX8/XK10Zf/EJa1qzX7pswJIsLOvsJ35qaNSIoBafliPJEFPF6ld/mOAOn3KKgjAq/t3dPwualDLVWDPxHUfvQQvvHK26/d3+dw8flmC1zBO90OgM7jqZ72iayHQCq7u/MTlXT7yXnYIDOu4mEe3TVrogp2iyBNSlDzUJMopL1F8G+Xlyeq/L6a/IUB736JkgkRhuFrB2tWrEmVM6GTzB629vHKvsCms/a9O1vk9N2b6nNvc9zy3nnWJZK2kQJHyUL0sjjjKKS9R/HUhBTT+qkbbKfT+rTrQed+mtm/C1BPHO3YoLth7y9XaoKrttdYVvoQFraMu5u+sXO8sOwTa1EDUG03sffpE7t67XiE+8gQUsUFPHB9w1gFAoLVovnPeXHyzptJ6nOP4j1X3bXJ8FDs/cbnmL+Jx17YxTI6Paq/p8FDFOkbhDwavH6pYWaS6zow68nDvbZ/ZhXqj77sc6hBFnoAi5qF6AR5dYEtF1lF8z8IO8wJ6/VfiukP8980L+sZJgdRRIrT93yrlVCkT3j2/FBrU866Hf3dy3rInweT4KNZeZLcRr5Qo83sPdAclTcHXPBtRaSKKPAFZ916Oy+T4KOa+eiMe9rU6DXs5srR0oljY/pS6qHj3LZjl4oplvtBkS5UxsTZkus7MXA3jX3sO9xyYT7QTfMe2rUCSZu2O8U/P+pMvbNF+Ls9GVJqIIk9A0fNQgy+HbsuddXP+qC+nl1IXlffeX+rIN7dh/VAldCH047+OwdF+OgX71kK9VbL/xHHjaDrb62RraHhVpHljcnxUu6PMuxGVFokUORHdTkQniGiZiLoiqf1OGnmoaRQ+2BC25c7S9x/15fTug3dfhjXDKYIs1KO5ZrzeKBuGq9YFOf75m8H7bNrhTR8+FRp0tb1OUeIktr3ue/3M7rm5e+5pkYwo1yTNWvk5gFsB/IUDWULJY6qfy2h+1lkwYVvurLatugwNVYMrf6GPP4feFltLvFopY8c1l1pnx/jx7mvwPt927SgO/PiNDveK56cOax0QpsSC785t147iyMkz7eEPuoUobHHI6pl11fO+X0ikyJn5ZQCgmD7JKGSt5HpB0kZTSQlL88pq26p6aa+/agRHTp5p+8SbzBhVvMxpNMHyLPGwY+u6DKp6qdcbTRz62dvdfumVn033pkxk3Amq3p0nj9U6/kbXrTLMwk3yzCY1zPphaLIreuYjJ6K7iWiWiGbPnNH3QtZRxFS/qGSdBWPacmexbfVv2acPn8LU9k14df8OTG3fhCeP1axK7k3XztblEsTLEDEde3S4iju3jSm3/zrr99xio8t94vmpdWmDXj+TsNzxsHcnrpsw7jM7qEOS0yLUIieiHwD4iOKfvsLM37U9ETM/AuARoFXZaS3hClkruV6QdTc21bxFnaWbNqYdWJgVGCzrV5nFXtvasB7lKrxz6e5XmQhvLdRx5OSZtgvDb3VGLcrxJvwAnV+HADSWLwQkdffH9t2JY+HGfWaz3n32G6GKnJk/3QtBwshayfUCl0OL45KX7arpRTcppi4XgcZkIGp9171Pn4g15ae2UMfDO7cqfeSexa1yYXio7vPqVSWreZ/lEqEEtH3pYW7GNN+duM/sIBhmvaQw6YdFT/WzoZ+6sSVF90LXVnpvq/CyO2x84l6v7723dGc/2FAmsipU0VWMqu6zrSzNZTbmmwdJ892J+8wWtQYjryQKdhLR7wL4MwAjAA4R0Twzb3ciWYBBiVLnxSLuJaqgl86KJKj7Y3uKyXYwxPBKHrJ3raNa5p4MQXeUCtWiZLrPNs2+bM8TlDGNdyd4/DBXD5CP3Wc/Id0PC0oeUzHjoMuWUKUWmrJAvICfbVOwSok6+mVHbSbm77IYloLoly8KUWVaP1TB3FdvjHQOF8Sdz9ovz3Av0XU/LIxrRbhALyP+aRd76HzhR06e6dqy60yOZea2ArAtdvEHCYFovlkCcP1VI1r5gzSZY92fqe2bWj3iLcnAJgMQP6MsWNkqSjw+0sa2gPQq4q/KHNl1YB73HJh3lsliCnoF3Q86C9XvV1W5EWxcHjatUj0YrWHWAKz/Js79ier2se6h4hgJXGaPKPIC0qsXR7VgeEZf1IIs/2ALf1rj8FBF2T9EFfSy9avGWQBUx/YoUavhlZ96o4lHI3ZGjHN/bL8LkF2gULcIlogwM1cTS7sHiGulgLiO+OvcJ2GKx7YgSzUzE2gtBu+eX+oqdKGVf/Nk8eTbdWAeayolDFcrkTIkbLI2VNkXD+/citf279C6LKJ6Mlyl++kKg9IMFJpcbDp3VlyXkhAdscgLiMuIv6nwxsbdYGNlmvzIjWVuKWZC2zL3W/1Tjx/vmCN6brGBaqWMh3Zutbb0bLM2dNkXul1DFFym+wHAvmdOtGXyipvSsnx1LrbZ02fxwOSFhfTeg8e7MorqjSb2PTO4k3t6hWStFBRXEX/TYGKTu8H/ubAZk7YzF6P0RFGdN+k1UWVfVMqEZpNhN7bhwkDg4aEKmFt+6ywzMlw8J7pnhICOBdV0nx+OsPAKemRmZ5/hKt88LNgIXMiRDqb/2VqZtjMXoxCUO6ypmo1CU+0cdK1jq5USAOpKj7zjU5e3pwBljatGc7pnhIGOAK7pPkvpfbqIj3zACfO3eylir+3fgYd8E4WiVJ1Obd/kfNhMUG5TJo9tumaUYOT5xjJuu3a043t52Sx58QnbpAXapJeafPv+a2Za1CWDJV3EIh9wovjb4+4CJsdHMXv6LB49+nrkAGGlRB0+cp18pp2FbbpmlBTEDcNVHDl5puv7JE0D1WX3xHGJhGU32VrsXsWs6t4FUz91qZJSep8uYpEPOL3q7/LA5Oa2RW/L+qEKpm/fgunPbwmVz7SzsE3X1A1EDhbleAuJ6zRQU3bPrgPzuH/GfkAGEL7bsi3kmRwfxZ3bxrp2VaoFVdUvRkrv00csciGV/i46n7SpjN4LFKp82DYphrqdha4PSlDR6bJbVL+bHB+1Pq4tpuweBvDo0dcxccUl1vcqbLcVZSF6YHIzJq64JHLmj5Te9wZR5IJzwrbsOgWTZCcQpkCmnjje4Z6plLvzrk0BUZVcrhs/hVnyweBiGGHXJGp7W9sFfxAbv2WNKHLBOWE+6bSsNqMCCTp4Az/HyfAwWfDX7X/eyqr34ypvPyijTn7pQNg/SB654BxdPjEBeHX/jl6LY8yV93LRbT5jgzIXXROwDe5AZuZq2qBiXHm846rmnb61UMe6lWKshcVs890FO6T7odAz8jY0wMYX7CpwqcxFX+aufHRdUNGkxONYy6rUy28ffb3980K9gfONZTy0c6t0ICwwosgF58SZSJNmu1ybhcXV4hNF8as+q8vqKRPFiiHYtNnttyHmg4gocsE5UVMa0+6vbrOwuBqHFkXx6zo8quSIM5gCsF9YpGCn2EiwU0iFKJkLSfurh5Xf2wRXXQVgbfrTAOaiKxdyeNgWOfVTwc4gTh6SYKeQOUmCo3HHjLnGrzzWVSv49flGVw9zD1dDOWzlCltYsrheaZGX5yEtpGmWkFui5jP76dW0JB0zc7WOlrJAK4BYKRHKpfBMlbRRWfj+rJUiWqwmizvr5yErEilyIpoGcDOADwC8AuDfMfOCC8GEwSFJPnMvx4yp0viCA6I9vD7ra1evylxh9lOBTli+/6COnUtqkX8fwH3MvERE3wBwH4AvJxdLGCSS+IWTWPNRUCmQsCZg79QbmN/T+6n2/UyYxd2r5yFvJFLkzPyc78ejAD6fTByhCKQRTIprNfaqOtE0v1RHvyuPLAizuAe1WtWlj/wPABxweDwhh7gaVuCKXjVpiro1L5ryKEqmR5jFPahNu0KzVojoBwA+ovinrzDzd1c+8xUAEwBuZc0BiehuAHcDwNjY2LWnT59OIreQEa5K2YuGaXp9ECLgoS8UZ7RZkTI9iiRrGsQu0WfmTzPzxxX/eUr89wF8FsCdOiW+cpxHmHmCmSdGRkaSfBchQwY1mKSbFK+Es9mdxMW2L3ke6FX//KKRNGvlJrSCm/+KmRfdiCTkmUENJqm27IsfLHWkHXoU7VoUbXHupywcVyT1kf85gNUAvk9EAHCUmf8wsVRCbhnUYBLQrUB02/xeXAuXPu1BXZz7iaRZK//UlSBCMRjUYJKKrK6F64DzIC/O/YKU6At9T1EyMmxJI+Dcb9eoX5ESfWEgyVu6pAvS8GmL37nYSBtboa8pUkaGLXkb3CFkjyhyoa8pWkaGDa56pwv9g7hWhMJj8u/2Y0aGBJyFIKLIhUIT5gPv14wM8WkLfsS1IhSaMB+4VAIKg4BY5EKhsfGBi/Uq9DtikQuFRjI4BEEUuVBwJINDEMS1IhQcyeAQBFHkQh8gPnBh0BHXiiAIQsERRS4IglBwRJELgiAUHFHkgiAIBUcUuSAIQsGRrBVBKAgy/EHQIYpcEApAPw7IENwhrhVBKAD9OCBDcIcockEoAP04IENwRyJFTkT/hYh+RkTzRPQcEW1wJZggCBeQ5mCCiaQW+TQzX8PMWwE8C+CrDmQSBCGANAcTTCQKdjLzr30/rgXAycQRBEGFNAcTTBBzMt1LRF8H8G8BvAPgemY+o/nc3QDuBoCxsbFrT58+nei8giAIgwYRHWPmia7fhylyIvoBgI8o/ukrzPxd3+fuA7CGmfeECTMxMcGzs7PhUguCIAhtdIo81LXCzJ+2PMd3ABwCEKrIBUEQBHckzVr5mO/HWwCcTCaOIAiCEJWklZ37iWgTgGUApwH8YXKRBEEQhCgkzVq5zZUggiAIQjwSZ63EOinRGbQs+F7wYQD/0KNzpYHIny0if7aI/J1cwcwjwV9mosh7CRHNqqK8RUHkzxaRP1tEfjuk14ogCELBEUUuCIJQcAZBkT+StQAJEfmzReTPFpHfgr73kQuCIPQ7g2CRC4Ig9DWiyAVBEArOQCjyog/AIKJpIjq58h3+JxENZy1TFIjodiI6QUTLRFSYVDIiuomIThHRL4hod9byRIGIvkVEvyKin2ctSxyI6HIiOkJEL688O1/KWqYoENEaIvoxER1fkX9fqucbBB85Ef2G1zudiP4DgN9i5sK0EyCiGwE8z8xLRPQNAGDmL2csljVE9JtotXH4CwD/iZlz3/qSiMoA/g+A3wHwJoCfALiDmf8+U8EsIaJ/CeBdAP+DmT+etTxRIaJLAVzKzD8log8BOAZgskDXnwCsZeZ3iagC4EcAvsTMR9M430BY5EUfgMHMzzHz0sqPRwFclqU8UWHml5m5aFOCPwngF8z8S2b+AMBfA/hcxjJZw8x/C+Bs1nLEhZnfZuafrvz/PwJ4GUBhpmhwi3dXfqys/Jea3hkIRQ60BmAQ0RsA7kSxR9L9AYC/yVqIAWAUwBu+n99EgRRJP0FEGwGMA3gxW0miQURlIpoH8CsA32fm1OTvG0VORD8gop8r/vscADDzV5j5cgCPAvijbKXtJkz+lc98BcASWt8hV9jIXzBI8btC7eT6ASK6GMCTAO4J7KxzDzM3V+YZXwbgk0SUmosraRvb3FD0ARhh8hPR7wP4LIB/zTkMbES4/kXhTQCX+36+DMBbGckykKz4lp8E8CgzP5W1PHFh5gUi+iGAmwCkEnzuG4vcRNEHYBDRTQC+DOAWZl7MWp4B4ScAPkZEVxLRRQC+CODpjGUaGFaChd8E8DIz/2nW8kSFiEa87DIiqgL4NFLUO4OStfIkgI4BGMxcy1Yqe4joFwBWA/h/K786WrCsm98F8GcARgAsAJhn5u3ZShUOEX0GwMMAygC+xcxfz1gka4joMQC/jVYb1f8LYA8zfzNToSJARP8CwP8G8BJa7y0A/DEzfy87qewhomsA/BVaz04JwEFm/lpq5xsERS4IgtDPDIRrRRAEoZ8RRS4IglBwRJELgiAUHFHkgiAIBUcUuSAIQsERRS4IglBwRJELgiAUnP8PQBrt4gts4m0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data and store feature vectors in array X and labels in array y.\n",
    "# Also display scatter plot of data.\n",
    "\n",
    "X, y = load('dataset.csv')\n",
    "#the load function already stores feature vectors in array X and labels in array y! \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>shuffle</code> that takes as input two arrays <code>X</code> and <code>y</code> with the same number of rows and returns two arrays containing the same data as the input arrays but with their rows randomly permuted. Hint: the <code>sklearn</code> function <code>random.shuffle</code> may be useful. However, if you shuffle the two arrays independently then labels in the <code>y</code> array won't correspond to the feature vectors in the <code>X</code> array. As an alternative, one approach is to combine the two arrays into a single array (e.g., with the <code>numpy</code> function either <code>hstack</code> or <code>concatenate</code>), randomly shuffle this array, and then split the array back into two arrays <code>X</code> and <code>y</code>.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.56030e-01,  9.82690e-01],\n",
       "        [-4.69200e-02,  4.77040e-01],\n",
       "        [ 1.59319e+00, -5.11220e-01],\n",
       "        [-1.84087e+00, -1.27958e+00],\n",
       "        [ 6.25670e-01, -8.57160e-01],\n",
       "        [ 4.43820e-01,  7.74630e-01],\n",
       "        [ 1.79769e+00,  6.40840e-01],\n",
       "        [ 1.84200e-02,  1.67644e+00],\n",
       "        [-1.64200e-02,  1.18839e+00],\n",
       "        [ 8.33920e-01,  4.59180e-01],\n",
       "        [-1.51790e-01,  5.88320e-01],\n",
       "        [ 1.55115e+00,  1.15670e-01],\n",
       "        [ 5.15050e-01,  3.85273e+00],\n",
       "        [-1.59443e+00, -5.99380e-01],\n",
       "        [ 1.66450e-01,  4.92450e-01],\n",
       "        [-9.08020e-01, -1.41230e+00],\n",
       "        [-3.95600e-02,  6.81500e-01],\n",
       "        [-1.08106e+00,  1.05315e+00],\n",
       "        [-9.64920e-01,  6.86050e-01],\n",
       "        [ 8.57660e-01, -1.59940e-01],\n",
       "        [ 9.24030e-01, -1.84900e-01],\n",
       "        [-1.11058e+00,  1.75227e+00],\n",
       "        [-1.22213e+00,  7.13000e-01],\n",
       "        [-1.55658e+00, -4.28120e-01],\n",
       "        [ 3.80000e-02,  1.20030e-01],\n",
       "        [ 1.17944e+00, -4.69180e-01],\n",
       "        [ 1.16316e+00,  1.02300e-02],\n",
       "        [ 9.54000e-01,  6.51390e-01],\n",
       "        [-1.55663e+00,  6.06010e-01],\n",
       "        [-1.03725e+00, -1.90340e-01],\n",
       "        [ 5.43600e-01, -3.70610e-01],\n",
       "        [ 1.99060e-01, -6.00220e-01],\n",
       "        [ 2.67050e-01,  8.89630e-01],\n",
       "        [ 7.15700e-02, -4.77660e-01],\n",
       "        [-2.75050e-01, -2.30192e+00],\n",
       "        [ 2.80990e-01, -6.22700e-01],\n",
       "        [ 3.99220e-01,  6.47200e-01],\n",
       "        [ 1.68393e+00, -4.58880e-01],\n",
       "        [ 3.57020e-01, -6.92910e-01],\n",
       "        [ 2.31466e+00, -1.86727e+00],\n",
       "        [ 1.07363e+00, -1.02652e+00],\n",
       "        [-8.58360e-01,  7.00310e-01],\n",
       "        [-2.45390e-01, -7.53740e-01],\n",
       "        [ 9.96500e-02, -5.03480e-01],\n",
       "        [ 7.21670e-01, -1.12905e+00],\n",
       "        [ 2.71580e-01, -1.27675e+00],\n",
       "        [-6.12790e-01, -3.87700e-01],\n",
       "        [ 5.57200e-02,  1.09419e+00],\n",
       "        [ 2.76690e-01,  8.27180e-01],\n",
       "        [ 8.13520e-01, -1.23086e+00],\n",
       "        [ 5.17660e-01, -7.25740e-01],\n",
       "        [ 2.56008e+00, -9.60600e-02],\n",
       "        [-1.08760e-01,  4.01710e-01],\n",
       "        [ 2.50490e-01,  3.46450e-01],\n",
       "        [-1.41537e+00, -4.20650e-01],\n",
       "        [-1.47859e+00,  1.14375e+00],\n",
       "        [ 1.14230e-01,  1.50300e-01],\n",
       "        [-9.89600e-01, -1.25790e-01],\n",
       "        [-9.85730e-01,  5.04050e-01],\n",
       "        [-6.11520e-01, -1.40666e+00],\n",
       "        [ 3.84070e-01, -3.26900e-02],\n",
       "        [-1.19130e+00,  6.56550e-01],\n",
       "        [ 5.19350e-01,  1.53274e+00],\n",
       "        [ 1.73596e+00,  1.97910e-01],\n",
       "        [ 1.31739e+00,  1.97600e-01],\n",
       "        [ 3.37600e-01, -4.11880e-01],\n",
       "        [-1.86870e-01, -4.39730e-01],\n",
       "        [ 8.22800e-02,  1.06548e+00],\n",
       "        [ 1.14877e+00, -1.73971e+00],\n",
       "        [ 1.70870e-01, -1.83980e-01],\n",
       "        [ 5.69770e-01,  4.47710e-01],\n",
       "        [ 7.38470e-01,  1.71370e-01],\n",
       "        [-7.44300e-02,  6.20670e-01],\n",
       "        [ 1.47789e+00, -5.18270e-01],\n",
       "        [-3.47100e-02, -1.16868e+00],\n",
       "        [ 7.85800e-01,  4.25460e-01],\n",
       "        [-1.62754e+00,  4.80800e-02],\n",
       "        [-1.72492e+00, -5.62290e-01],\n",
       "        [ 1.17930e+00,  6.75200e-02],\n",
       "        [ 6.81950e-01, -3.10270e-01],\n",
       "        [ 3.43620e-01, -1.76304e+00],\n",
       "        [ 1.38216e+00,  6.48710e-01],\n",
       "        [-1.37767e+00, -9.37830e-01],\n",
       "        [-1.44808e+00, -1.40746e+00],\n",
       "        [ 4.12930e-01, -5.63720e-01],\n",
       "        [-4.34500e-01, -3.09170e-01],\n",
       "        [ 7.56990e-01, -9.22170e-01],\n",
       "        [-5.30260e-01, -7.92870e-01],\n",
       "        [ 1.84300e-02,  3.47580e-01],\n",
       "        [ 1.96473e+00,  3.52600e-02],\n",
       "        [ 1.77700e-01, -1.33534e+00],\n",
       "        [ 1.52312e+00,  5.38910e-01],\n",
       "        [ 2.59720e-01, -9.04320e-01],\n",
       "        [-9.81510e-01,  4.62100e-01],\n",
       "        [-4.71930e-01,  1.08895e+00],\n",
       "        [-1.90200e-02, -1.00253e+00],\n",
       "        [ 2.24450e-01,  1.04710e+00],\n",
       "        [-1.25154e+00,  1.44376e+00],\n",
       "        [ 2.70460e-01, -5.02400e-02],\n",
       "        [-6.37390e-01,  1.18902e+00],\n",
       "        [ 6.45480e-01,  2.16325e+00],\n",
       "        [-4.85360e-01,  8.18700e-02],\n",
       "        [-7.73790e-01, -1.24465e+00],\n",
       "        [ 1.27766e+00, -5.91570e-01],\n",
       "        [-3.60000e-03, -1.15836e+00],\n",
       "        [-1.58010e-01, -4.26880e-01],\n",
       "        [-2.06744e+00, -8.91200e-02],\n",
       "        [ 6.21810e-01, -1.57022e+00],\n",
       "        [-2.47164e+00, -7.96900e-01],\n",
       "        [-1.12330e-01, -2.20970e-01],\n",
       "        [-1.77872e+00,  1.49604e+00],\n",
       "        [-1.32023e+00,  1.83146e+00],\n",
       "        [ 6.98000e-02, -3.85310e-01],\n",
       "        [ 7.71700e-01, -2.84854e+00],\n",
       "        [ 6.42720e-01,  1.32915e+00],\n",
       "        [-1.47852e+00, -7.19840e-01],\n",
       "        [ 6.50200e-01, -9.91800e-02],\n",
       "        [-4.71040e-01,  2.32050e-01],\n",
       "        [ 5.21940e-01,  2.96980e-01],\n",
       "        [ 4.08250e-01, -1.70258e+00],\n",
       "        [ 5.24000e-03,  4.69800e-02],\n",
       "        [-1.12272e+00,  3.82410e-01],\n",
       "        [ 1.50236e+00,  7.40900e-02],\n",
       "        [ 6.24120e-01,  6.28350e-01],\n",
       "        [-1.60748e+00,  1.84630e-01],\n",
       "        [ 2.15318e+00, -7.67350e-01],\n",
       "        [-4.46180e-01, -1.88954e+00],\n",
       "        [-3.46800e-02,  2.34210e-01],\n",
       "        [-7.20100e-02,  1.00353e+00],\n",
       "        [ 2.35610e-01,  7.70870e-01],\n",
       "        [ 3.81940e-01,  4.30040e-01],\n",
       "        [ 5.15040e-01,  5.13790e-01],\n",
       "        [-5.53650e-01, -1.19788e+00],\n",
       "        [ 9.70800e-02,  9.68640e-01],\n",
       "        [-7.90470e-01,  4.71470e-01],\n",
       "        [-1.72630e-01,  8.83660e-01],\n",
       "        [-8.98410e-01,  4.91920e-01],\n",
       "        [ 1.28100e-01, -6.81050e-01],\n",
       "        [ 3.38500e-01, -4.15290e-01],\n",
       "        [ 1.95850e-01, -9.78370e-01],\n",
       "        [ 1.73180e-01,  3.85320e-01],\n",
       "        [-2.69689e+00, -5.42900e-02],\n",
       "        [ 8.12860e-01,  6.29630e-01],\n",
       "        [-1.34819e+00,  7.43260e-01],\n",
       "        [ 8.69610e-01,  1.35564e+00],\n",
       "        [ 9.70000e-02,  5.95160e-01],\n",
       "        [-1.61290e-01,  4.04050e-01],\n",
       "        [-9.19420e-01,  1.54993e+00],\n",
       "        [ 4.94030e-01,  2.60670e-01],\n",
       "        [ 1.39300e-02, -2.41300e-02],\n",
       "        [-9.74680e-01,  7.87080e-01],\n",
       "        [ 6.98220e-01,  3.93490e-01],\n",
       "        [ 1.86770e-01, -7.55380e-01],\n",
       "        [-1.30447e+00,  6.69670e-01],\n",
       "        [-1.28996e+00, -1.29508e+00],\n",
       "        [ 1.30000e-02,  1.45353e+00],\n",
       "        [ 1.46565e+00, -2.25780e-01],\n",
       "        [ 3.07888e+00,  1.11957e+00],\n",
       "        [ 7.10960e-01,  4.44260e-01],\n",
       "        [ 6.47690e-01,  1.52303e+00],\n",
       "        [-1.35986e+00,  7.46250e-01],\n",
       "        [ 6.90140e-01, -4.01220e-01],\n",
       "        [ 1.44698e+00,  1.96550e-01],\n",
       "        [-2.08120e-01, -4.93000e-01],\n",
       "        [-1.85100e-02, -2.88660e-01],\n",
       "        [ 2.57336e+00,  5.92200e-02],\n",
       "        [ 3.66600e-01, -9.39880e-01],\n",
       "        [-6.26800e-02,  9.55140e-01],\n",
       "        [ 1.50076e+00,  8.50220e-01],\n",
       "        [ 6.32410e-01,  9.72550e-01],\n",
       "        [-2.23460e-01,  7.14000e-01],\n",
       "        [-4.59360e-01, -8.49840e-01],\n",
       "        [-1.60645e+00,  2.03460e-01],\n",
       "        [ 8.20480e-01,  5.07270e-01],\n",
       "        [ 1.13520e-01,  6.62130e-01],\n",
       "        [-1.55066e+00,  6.85600e-02],\n",
       "        [-1.22500e-02, -8.97250e-01],\n",
       "        [ 2.59880e-01,  7.81820e-01],\n",
       "        [ 6.14170e-01,  7.57510e-01],\n",
       "        [-1.07089e+00,  4.82470e-01],\n",
       "        [-7.15300e-01,  6.79600e-01],\n",
       "        [-1.39857e+00,  5.62970e-01],\n",
       "        [ 3.10910e-01,  1.47536e+00],\n",
       "        [ 6.32780e-01,  2.27069e+00],\n",
       "        [ 3.42730e-01,  4.56750e-01],\n",
       "        [-3.27500e-02, -5.43420e-01],\n",
       "        [-2.09000e-02,  1.17330e-01],\n",
       "        [-1.35000e-02, -1.05771e+00],\n",
       "        [-7.01700e-02, -1.66096e+00],\n",
       "        [ 1.04955e+00, -5.35240e-01],\n",
       "        [ 1.58602e+00, -1.23782e+00],\n",
       "        [-1.40751e+00, -7.77820e-01],\n",
       "        [-1.26088e+00,  9.17860e-01],\n",
       "        [ 3.22720e-01, -8.27230e-01],\n",
       "        [-2.64660e-01,  2.72017e+00],\n",
       "        [-9.90540e-01, -5.66300e-01],\n",
       "        [ 1.07868e+00, -3.85100e-02],\n",
       "        [ 8.99600e-01,  3.07300e-01],\n",
       "        [-2.30930e-01,  6.96210e-01],\n",
       "        [-7.04340e-01, -1.40846e+00],\n",
       "        [-1.52553e+00, -6.91910e-01],\n",
       "        [-2.61975e+00,  8.21900e-01],\n",
       "        [ 6.13520e-01, -1.02279e+00],\n",
       "        [ 2.49380e-01,  1.57745e+00],\n",
       "        [ 4.96710e-01, -1.38260e-01],\n",
       "        [ 2.52693e+00, -5.30870e-01],\n",
       "        [-8.22220e-01,  2.43690e-01],\n",
       "        [ 9.93300e-02,  7.51390e-01],\n",
       "        [ 7.27630e-01,  5.19500e-02],\n",
       "        [ 1.14282e+00,  7.51930e-01],\n",
       "        [-1.70338e+00, -5.55500e-02],\n",
       "        [-9.75870e-01,  1.05364e+00],\n",
       "        [ 5.70890e-01,  1.13557e+00],\n",
       "        [-1.92360e-01,  3.01550e-01],\n",
       "        [-1.28043e+00,  1.75479e+00],\n",
       "        [-2.41240e-01,  3.52060e-01],\n",
       "        [-4.46430e-01,  1.94090e-01],\n",
       "        [-2.59040e-01, -1.96350e-01],\n",
       "        [-1.20030e+00, -3.34500e-01],\n",
       "        [-6.51420e-01, -4.83890e-01],\n",
       "        [ 1.54751e+00,  1.79588e+00],\n",
       "        [-2.19670e-01,  3.57110e-01],\n",
       "        [ 4.73240e-01, -7.28300e-02],\n",
       "        [ 3.68670e-01, -3.93340e-01],\n",
       "        [ 2.02920e-01, -1.51574e+00],\n",
       "        [ 9.50420e-01, -5.76900e-01],\n",
       "        [ 3.61400e-01,  1.53804e+00],\n",
       "        [-6.26970e-01,  1.81245e+00],\n",
       "        [ 4.78980e-01,  3.33660e-01],\n",
       "        [-3.58300e-02,  1.56464e+00],\n",
       "        [-6.60800e-02, -1.21102e+00],\n",
       "        [-1.87079e+00, -3.51510e-01],\n",
       "        [ 5.82100e-02, -1.14297e+00],\n",
       "        [ 3.26130e-01, -1.25111e+00],\n",
       "        [-4.55900e-02,  2.43340e-01],\n",
       "        [ 2.22130e-01, -4.78750e-01],\n",
       "        [ 2.44575e+00,  1.29220e-01],\n",
       "        [-9.26930e-01, -5.95300e-02],\n",
       "        [-1.69246e+00,  1.52955e+00],\n",
       "        [ 2.14394e+00,  6.33920e-01],\n",
       "        [-5.50310e-01, -6.71620e-01],\n",
       "        [ 5.96300e-02, -6.46940e-01],\n",
       "        [ 1.05842e+00, -1.75874e+00],\n",
       "        [ 1.45114e+00,  9.59270e-01],\n",
       "        [ 5.86860e-01,  2.19046e+00],\n",
       "        [-9.49400e-01,  2.63238e+00],\n",
       "        [-1.66941e+00,  5.43360e-01],\n",
       "        [ 1.47654e+00,  1.38009e+00],\n",
       "        [ 9.26180e-01,  1.90942e+00],\n",
       "        [ 1.40279e+00, -1.40185e+00],\n",
       "        [-3.76300e-02,  1.10330e+00],\n",
       "        [-2.34150e-01, -2.34140e-01],\n",
       "        [-5.39760e-01, -7.78300e-01],\n",
       "        [-1.15099e+00,  3.75700e-01],\n",
       "        [-1.51937e+00, -4.84230e-01],\n",
       "        [-3.07780e-01,  2.19150e-01],\n",
       "        [ 9.96270e-01, -4.93760e-01],\n",
       "        [-1.51519e+00,  1.36687e+00],\n",
       "        [-4.74950e-01, -6.53330e-01],\n",
       "        [ 9.38280e-01, -5.16040e-01],\n",
       "        [-2.38950e-01, -9.07560e-01],\n",
       "        [ 1.42050e+00, -5.70750e-01],\n",
       "        [ 7.91030e-01, -9.09390e-01],\n",
       "        [-1.28030e+00,  8.72460e-01],\n",
       "        [-5.89360e-01,  8.49600e-01],\n",
       "        [ 6.54370e-01, -5.55800e-02],\n",
       "        [ 2.08380e-01, -2.04173e+00],\n",
       "        [ 9.15400e-01,  3.28750e-01],\n",
       "        [-4.79170e-01, -1.85660e-01],\n",
       "        [-6.76920e-01,  6.11680e-01],\n",
       "        [ 7.73700e-02, -8.61280e-01],\n",
       "        [ 7.47290e-01,  6.10370e-01],\n",
       "        [-1.91877e+00, -2.65100e-02],\n",
       "        [-1.29468e+00,  1.16083e+00],\n",
       "        [ 1.88619e+00,  1.74580e-01],\n",
       "        [ 1.55050e+00, -9.98350e-01],\n",
       "        [ 8.25420e-01,  8.13510e-01],\n",
       "        [ 9.61200e-02, -4.62280e-01],\n",
       "        [ 2.29890e+00, -3.62840e-01],\n",
       "        [ 6.81890e-01,  1.84671e+00],\n",
       "        [ 2.27460e-01,  1.30714e+00],\n",
       "        [ 3.94450e-01, -4.20980e-01],\n",
       "        [ 8.22060e-01,  1.89679e+00],\n",
       "        [ 8.22540e-01, -1.22084e+00],\n",
       "        [ 1.72754e+00,  4.36320e-01],\n",
       "        [ 2.85870e-01,  3.34460e-01],\n",
       "        [-3.21640e-01,  2.07675e+00],\n",
       "        [ 5.29800e-01,  1.44157e+00],\n",
       "        [ 1.64497e+00, -2.49040e-01],\n",
       "        [-2.69870e-01, -9.78760e-01],\n",
       "        [ 1.20121e+00, -4.08080e-01],\n",
       "        [-1.00162e+00, -2.81100e-01],\n",
       "        [ 1.08305e+00,  1.05380e+00],\n",
       "        [-6.50640e-01, -4.87130e-01],\n",
       "        [ 1.09390e-01,  7.25770e-01],\n",
       "        [-4.01600e-02, -1.43078e+00],\n",
       "        [ 8.40640e-01, -6.52620e-01],\n",
       "        [-4.83190e-01,  1.57399e+00],\n",
       "        [ 5.90650e-01,  1.10870e+00],\n",
       "        [ 2.44970e-01, -5.06940e-01],\n",
       "        [-2.12390e+00, -5.25760e-01],\n",
       "        [-2.40330e-01, -3.74820e-01],\n",
       "        [ 8.71120e-01, -3.26020e-01],\n",
       "        [-3.24127e+00, -1.02439e+00],\n",
       "        [ 6.58540e-01,  2.01020e+00],\n",
       "        [-1.06762e+00, -1.42380e-01],\n",
       "        [ 2.45100e-02,  4.98000e-01],\n",
       "        [ 1.57921e+00,  7.67430e-01],\n",
       "        [ 6.38590e-01, -1.66152e+00],\n",
       "        [-8.32360e-01,  4.71420e-01],\n",
       "        [ 1.15811e+00,  7.91660e-01],\n",
       "        [-1.34445e+00, -9.18650e-01],\n",
       "        [-1.15650e-01, -3.01100e-01],\n",
       "        [-8.21500e-02,  1.11730e+00],\n",
       "        [-2.08193e+00,  1.69646e+00],\n",
       "        [-3.48650e-01, -3.49260e-01],\n",
       "        [ 4.55700e-02, -6.51600e-01],\n",
       "        [-7.16000e-02, -3.72200e-02],\n",
       "        [ 8.30340e-01, -8.56080e-01],\n",
       "        [ 4.29620e-01,  2.07690e-01],\n",
       "        [ 6.45380e-01,  1.36863e+00],\n",
       "        [ 8.12530e-01,  1.35624e+00],\n",
       "        [-9.23230e-01, -1.35168e+00],\n",
       "        [ 3.32310e-01, -7.48490e-01],\n",
       "        [-1.23695e+00, -1.32046e+00],\n",
       "        [-4.60640e-01,  1.05712e+00],\n",
       "        [ 1.84664e+00, -1.07008e+00],\n",
       "        [ 8.72320e-01,  1.83340e-01],\n",
       "        [ 2.18980e+00, -8.08300e-01],\n",
       "        [-3.42690e-01, -3.71440e-01],\n",
       "        [ 5.76560e-01,  3.11250e-01],\n",
       "        [ 3.61640e-01, -6.45120e-01],\n",
       "        [ 5.04990e-01,  8.65760e-01],\n",
       "        [-2.02514e+00,  1.86450e-01],\n",
       "        [ 1.00629e+00, -5.76890e-01],\n",
       "        [-7.97000e-03,  1.47994e+00],\n",
       "        [ 6.75300e-02, -1.42475e+00],\n",
       "        [ 3.07800e-01, -1.71017e+00],\n",
       "        [ 5.93100e-01, -3.09550e-01],\n",
       "        [-1.37932e+00, -7.30930e-01],\n",
       "        [ 3.24080e-01, -3.85080e-01],\n",
       "        [-5.92390e-01, -8.63990e-01],\n",
       "        [-3.62440e-01, -1.11967e+00],\n",
       "        [ 3.71150e-01, -6.03990e-01],\n",
       "        [-3.63610e-01, -5.69500e-02],\n",
       "        [-6.00640e-01, -2.91690e-01],\n",
       "        [ 2.89170e-01,  2.45530e+00],\n",
       "        [ 1.03100e+00,  9.31280e-01],\n",
       "        [-2.20960e-01,  2.68900e-02],\n",
       "        [ 4.40010e-01, -5.02050e-01],\n",
       "        [-4.52310e-01, -2.42388e+00],\n",
       "        [-1.71313e+00,  1.35387e+00],\n",
       "        [ 5.77070e-01, -2.03050e-01],\n",
       "        [-6.76390e-01,  1.80094e+00],\n",
       "        [ 9.63380e-01,  4.12780e-01],\n",
       "        [ 1.86577e+00,  4.73830e-01],\n",
       "        [ 4.81010e-01,  2.23880e-01],\n",
       "        [ 5.11000e-03, -2.34590e-01],\n",
       "        [-1.18326e+00, -2.03923e+00],\n",
       "        [-6.37740e-01, -5.31000e-01],\n",
       "        [-5.73660e-01, -5.46860e-01],\n",
       "        [-7.59130e-01,  1.50390e-01],\n",
       "        [ 4.85200e-02, -8.30950e-01],\n",
       "        [ 1.66547e+00,  1.01437e+00],\n",
       "        [ 2.11020e-01, -9.67100e-02],\n",
       "        [-8.83860e-01,  1.53730e-01],\n",
       "        [ 2.57550e-01, -7.44500e-02],\n",
       "        [-1.76950e-01, -7.98300e-01],\n",
       "        [ 5.47100e-01, -2.02190e-01],\n",
       "        [-1.32819e+00,  1.96860e-01],\n",
       "        [ 1.26691e+00, -7.07670e-01],\n",
       "        [-2.52570e-01, -1.24778e+00],\n",
       "        [ 8.23170e-01,  7.33200e-02],\n",
       "        [-8.75620e-01, -1.38280e+00],\n",
       "        [ 6.86260e-01, -1.61272e+00],\n",
       "        [ 1.81870e-01,  2.48220e-01],\n",
       "        [ 8.65900e-02, -1.55680e-01],\n",
       "        [ 1.88202e+00,  1.34542e+00],\n",
       "        [-4.40040e-01,  1.30740e-01],\n",
       "        [ 3.26930e-01, -2.19100e-01],\n",
       "        [ 1.84896e+00,  1.12657e+00],\n",
       "        [ 8.35690e-01, -1.12971e+00],\n",
       "        [ 1.30548e+00,  2.10000e-02],\n",
       "        [-9.53000e-02,  2.79020e-01],\n",
       "        [-7.56350e-01, -1.42225e+00],\n",
       "        [-1.06230e+00,  4.73590e-01],\n",
       "        [ 3.57790e-01,  5.60780e-01],\n",
       "        [-1.07030e-01, -1.03524e+00],\n",
       "        [ 9.17600e-02, -1.98757e+00],\n",
       "        [ 1.06667e+00,  1.16930e+00],\n",
       "        [ 1.44127e+00, -1.43586e+00],\n",
       "        [ 1.98080e-01, -1.44360e-01],\n",
       "        [ 6.52320e-01, -1.57639e+00],\n",
       "        [-3.92110e-01, -1.46351e+00],\n",
       "        [ 1.24609e+00, -2.07339e+00],\n",
       "        [ 5.00920e-01, -9.77560e-01],\n",
       "        [ 4.13430e-01,  1.87680e+00],\n",
       "        [-5.30500e-01, -5.75820e-01],\n",
       "        [ 1.03754e+00, -5.10020e-01],\n",
       "        [-2.57380e-01, -1.66858e+00],\n",
       "        [ 1.20651e+00, -8.16940e-01],\n",
       "        [ 1.25576e+00, -8.94610e-01],\n",
       "        [-4.45500e-01,  1.45338e+00],\n",
       "        [-6.46570e-01, -1.08155e+00],\n",
       "        [ 3.80200e-01,  6.10590e-01],\n",
       "        [ 2.83200e-02,  2.97600e-02],\n",
       "        [ 8.29410e-01, -2.21114e+00],\n",
       "        [-2.69410e-01,  7.17540e-01],\n",
       "        [-2.03812e+00, -1.00809e+00],\n",
       "        [ 2.14090e-01, -1.24574e+00],\n",
       "        [ 2.41960e-01, -1.91328e+00],\n",
       "        [ 1.15860e+00, -8.20680e-01],\n",
       "        [-4.87610e-01, -4.32560e-01],\n",
       "        [-2.68890e-01, -1.10653e+00],\n",
       "        [ 2.43800e-01, -5.64080e-01],\n",
       "        [-1.67120e-01,  1.46710e-01],\n",
       "        [-7.63260e-01, -1.80488e+00],\n",
       "        [ 1.91100e-01,  4.64400e-02],\n",
       "        [ 1.63241e+00, -1.43014e+00],\n",
       "        [-5.13870e-01, -1.05921e+00],\n",
       "        [-5.17290e-01,  1.40935e+00],\n",
       "        [ 1.62862e+00, -1.38010e+00],\n",
       "        [-2.59590e-01, -1.50314e+00],\n",
       "        [ 1.96520e-01,  7.09000e-01],\n",
       "        [ 2.89770e-01,  2.07540e+00],\n",
       "        [ 7.68200e-02, -1.28299e+00],\n",
       "        [ 1.57957e+00, -5.22860e-01],\n",
       "        [ 3.24170e-01, -1.30140e-01],\n",
       "        [ 6.07900e-01,  1.86610e-01],\n",
       "        [-1.58390e+00,  7.60410e-01],\n",
       "        [ 9.84320e-01, -2.13990e-01],\n",
       "        [ 5.22840e-01, -5.73700e-01],\n",
       "        [-5.76770e-01,  7.55390e-01],\n",
       "        [ 2.24090e-01,  1.25900e-02],\n",
       "        [-6.62620e-01,  5.70600e-01],\n",
       "        [-4.94600e-02,  6.74820e-01],\n",
       "        [-4.20190e-01, -2.81780e-01],\n",
       "        [ 1.02916e+00,  4.72600e-01],\n",
       "        [-2.45740e-01, -2.72720e-01],\n",
       "        [ 3.41760e-01,  1.87617e+00],\n",
       "        [ 1.76545e+00,  4.04980e-01],\n",
       "        [-7.30370e-01,  2.16460e-01],\n",
       "        [ 9.75120e-01, -1.47060e-01],\n",
       "        [-5.55200e-01,  1.88116e+00],\n",
       "        [-1.27920e-01, -9.55540e-01],\n",
       "        [ 1.14927e+00, -7.03180e-01],\n",
       "        [-6.01710e-01,  1.85228e+00],\n",
       "        [ 5.59790e-01,  1.08078e+00],\n",
       "        [ 3.31260e-01,  9.75550e-01],\n",
       "        [ 1.20300e-01,  5.14440e-01],\n",
       "        [-9.66980e-01, -4.77100e-02],\n",
       "        [ 9.76800e-02, -7.73010e-01],\n",
       "        [ 1.03028e+00,  2.38790e-01],\n",
       "        [ 1.68714e+00,  8.81640e-01],\n",
       "        [ 2.12216e+00,  1.03247e+00],\n",
       "        [ 2.93070e-01, -7.14350e-01],\n",
       "        [-1.01210e+00, -1.65486e+00],\n",
       "        [ 1.32970e-01, -7.00120e-01],\n",
       "        [-3.20350e-01,  4.24170e-01],\n",
       "        [ 2.79970e-01, -1.12549e+00],\n",
       "        [ 7.58000e-02, -6.77160e-01],\n",
       "        [ 1.16778e+00,  2.54420e-01],\n",
       "        [-8.18220e-01,  2.09239e+00],\n",
       "        [ 8.95190e-01,  6.35170e-01],\n",
       "        [ 1.56552e+00, -6.57500e-02],\n",
       "        [-3.35780e-01,  1.66902e+00],\n",
       "        [-1.01283e+00,  3.14250e-01],\n",
       "        [-3.42710e-01, -8.02280e-01],\n",
       "        [ 9.35680e-01,  1.27156e+00],\n",
       "        [-1.53411e+00,  1.27768e+00],\n",
       "        [ 1.50340e+00,  8.77360e-01],\n",
       "        [-2.47180e-01, -6.81980e-01],\n",
       "        [ 1.03184e+00, -1.48556e+00],\n",
       "        [-1.14540e-01,  1.23782e+00],\n",
       "        [-5.22720e-01,  1.04901e+00],\n",
       "        [ 1.19505e+00, -1.52319e+00],\n",
       "        [-6.23140e-01, -5.55480e-01],\n",
       "        [ 8.70500e-02, -2.99010e-01],\n",
       "        [ 4.93320e-01,  1.84840e-01],\n",
       "        [ 7.07750e-01, -5.62470e-01],\n",
       "        [ 2.13303e+00, -1.95209e+00],\n",
       "        [-1.08106e+00,  6.15940e-01],\n",
       "        [ 2.06075e+00,  1.75534e+00],\n",
       "        [ 6.42800e-02, -1.07774e+00],\n",
       "        [ 7.11610e-01, -1.12464e+00],\n",
       "        [-2.55500e-02,  1.17273e+00],\n",
       "        [ 2.96120e-01,  2.61060e-01],\n",
       "        [-4.89440e-01,  1.04416e+00],\n",
       "        [ 2.07526e+00, -6.89190e-01],\n",
       "        [ 2.08860e-01, -1.95967e+00],\n",
       "        [-6.61790e-01,  8.52430e-01],\n",
       "        [ 1.39936e+00,  9.24630e-01],\n",
       "        [-4.63420e-01, -4.65730e-01],\n",
       "        [-2.65097e+00,  1.09151e+00],\n",
       "        [-7.71000e-02,  3.41150e-01],\n",
       "        [ 2.87400e-02,  1.27845e+00],\n",
       "        [-6.99730e-01,  2.13980e-01],\n",
       "        [ 5.83930e-01, -3.59290e-01],\n",
       "        [-8.46790e-01, -1.51485e+00],\n",
       "        [-1.02123e+00,  7.08360e-01]]),\n",
       " array([ 1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "         1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "         1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "         1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1.,  1.,  1.,  1.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle function takes two arrays, X and y, as input,\n",
    "# and returns versions of the two arrays where their rows have been randomly permuted\n",
    "\n",
    "def shuffle(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    shuffled_X = np.empty(X.shape, dtype=X.dtype)\n",
    "    shuffled_y = np.empty(y.shape, dtype=y.dtype)\n",
    "    permutation = np.random.permutation(len(X))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_X[new_index] = X[old_index]\n",
    "        shuffled_y[new_index] = y[old_index]\n",
    "    return shuffled_X, shuffled_y\n",
    "shuffle(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code to split the data into four arrays (<code>X_train</code>, <code>y_train</code>, <code>X_test</code>, and <code>y_test</code>) so that 60% of the data corresponds to <em>training</em> data and 40% of the data corresponds to <em>testing</em> data. Of course, before splitting the data into <em>training</em> data and <em>testing</em> data, you should first shuffle the arrays <code>X</code> and <code>y</code> to guard against the case when the data was stored in the file in some sorted order (we want the <em>training</em> and <em>testing</em> data both to be representative of the entire data distribution).</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data and then separate data into 60% training data and 40% testing data\n",
    "\n",
    "X,y = shuffle(X, y)\n",
    "train_60_percent = int(X.shape[0]*0.6)\n",
    "\n",
    "X_train = X[0:train_60_percent]\n",
    "y_train = y[0:train_60_percent]\n",
    "\n",
    "X_test = X[train_60_percent:]\n",
    "y_test = y[train_60_percent:]\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>In the next part, you will be writing a function to train a perceptron. For now, you'll write a <em>simplified</em> version where the bias term is set to zero and never updated. Also, in this simplified version, you will <em>not</em> shuffle the data each epoch. In later versions, you will write more advanced perceptron training functions that update the bias term, shuffle the data each epoch, and compute <em>averaged</em> perceptrons. Ultimately, we'll execute both simplified and advanced versions of the perceptron training algorithm and see how the results change as we add more advanced aspects to the training algorithm.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>perceptron_train_version1</code> that trains a perceptron. The function should take as input an array <code>X</code> of feature vectors and an array <code>y</code> of labels. It should implement the perceptron training algorithm which learns a weight vector <code>w</code> that defines a separating hyperplane. The number of epochs should be 20. The function should <em>not</em> learn or update a bias term (we'll get to this later). The function should set a bias term <code>b</code> to be 0 and never change it. The function also should <em>not</em> shuffle data at any point (we'll get to this later, too). The function should return two elements, the learned weight vector <code>w</code> and a bias term <code>b</code>, which simply has the value of zero.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The perceptron_train_version1 function takes an array X of feature vectors and an array y of labels as input.\n",
    "# The function trains a perceptron. The number of epochs should be 20.\n",
    "# The function returns the weight vector w that it learns as well as a bias term of 0.\n",
    "\n",
    "def perceptron_train_version1(X, y):\n",
    "    b = 0 #bias \n",
    "    w = np.zeros(X.shape[1]) #weight vector \n",
    "    epochs = 20\n",
    "    while(epochs>0):\n",
    "        counter = 0 \n",
    "        for i in range(len(X[:, 0])):\n",
    "            if (y[i]*np.dot(w,X[i]))<=0:\n",
    "                w = w + y[i]*X[i]\n",
    "                counter += 1\n",
    "        if counter ==0:\n",
    "            epochs =0\n",
    "        epochs -= 1\n",
    "    return w,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>predict</code> that predicts the class of a data point. The function should take three inputs: a weight vector <code>w</code>, a bias term <code>b</code>, and a single feature vector <code>x</code>. The weight vector <code>w</code> and the feature vector <code>x</code> should have the same size. The function should compute the appropriate weighted sum and then apply the activation function so that either -1 or 1 is returned.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a weight vector w and a bias term b, the predict function \n",
    "# predicts the class of a data point x, returning either -1 or 1.\n",
    "\n",
    "def predict(w, b, x):\n",
    "    if ((np.dot(w,x) + b) > 0):\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = -1\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>score</code> that takes four inputs, a weight vector <code>w</code>, a bias term <code>b</code>, an array <code>X</code> of feature vectors and an array <code>y</code> of labels. The function uses the weight vector <code>w</code> and the bias term <code>b</code> to make classification predictions for each feature vector in <code>X</code>. The predictions are compared to the labels in <code>y</code> and the accuracy is returned, i.e., the percentage of predictions that correctly correspond to labels in <code>y</code> is returned.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The score function uses the weight vector w and the bias term b \n",
    "# to predict the class of each feature vector in X.\n",
    "# The predicted classes are compared to the labels in y and the accuracy of the predictions is returned.\n",
    "\n",
    "def score(w, b, X, y) :\n",
    "    predictions = []\n",
    "    for i in range(len(X[:,0])):\n",
    "        prediction = predict(w,b,X[i])\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i]==y[i]:\n",
    "            counter += 1\n",
    "    accuracy_score = counter/(len(y))\n",
    "    return accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Use your <code>perceptron_train_version1</code> function to train a perceptron on the <em>training</em> data. Then use the <code>score</code> function to assess the accuracy of the perceptron first on the <em>training</em> data and second on the <em>testing</em> data.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433333333333333\n",
      "0.665\n"
     ]
    }
   ],
   "source": [
    "# Assess the accuracy of your perceptron (version 1) on the training data and on the testing data\n",
    "\n",
    "w,b = perceptron_train_version1(X_train, y_train)\n",
    "training_accuracy_score = score(w, b, X_train, y_train)\n",
    "testing_accuracy_score = score(w, b, X_test, y_test)\n",
    "print(training_accuracy_score)\n",
    "print(testing_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version1</em> perceptron on the <em>training</em> data?</u></font></P>\n",
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version1</em> perceptron on the <em>testing</em> data?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy (version 1): 64.33% \n",
    "Testing accuracy (version 1): 66.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>perceptron_train_version2</code> that trains a perceptron but this time, unlike version 1 above, the function should update the bias term. The function should take as input an array <code>X</code> of feature vectors and an array <code>y</code> of labels. It should implement the perceptron training algorithm which learns a weight vector <code>w</code> <em>and</em> a bias term <code>b</code>. The number of epochs should be 20. The function should <em>not</em> shuffle data at any point (we'll get to this later). The function should return two elements, the learned weight vector <code>w</code> and the learned bias term <code>b</code>.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.28976, 0.2605 ]), 2.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The perceptron_train_version2 function takes an array X of feature vectors and an array y of labels as input.\n",
    "# The function trains a perceptron. The number of epochs should be 20.\n",
    "# The function returns the weight vector w and the bias term b that it learns.\n",
    "\n",
    "def perceptron_train_version2(X, y):\n",
    "    b = 0\n",
    "    w = np.zeros(X.shape[1])\n",
    "    epochs = 20\n",
    "    while(epochs>0):\n",
    "        counter = 0 \n",
    "        for i in range(len(X[:, 0])):\n",
    "            if (y[i]*(np.dot(w,X[i])+b))<=0:\n",
    "                w = w + y[i]* X[i]\n",
    "                b = b + y[i]\n",
    "                counter += 1\n",
    "        if counter == 0:\n",
    "            epochs= 0\n",
    "        epochs -= 1\n",
    "    return w,b\n",
    "                    \n",
    "perceptron_train_version2(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Use your <code>perceptron_train_version2</code> function to train a perceptron on the <em>training</em> data. Then use the <code>score</code> function to assess the accuracy of the perceptron first on the <em>training</em> data and second on the <em>testing</em> data.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "# Assess the accuracy of your perceptron (version 2) on the training data and on the testing data\n",
    "\n",
    "w,b = perceptron_train_version2(X_train, y_train)\n",
    "training_accuracy_score = score(w, b, X_train, y_train)\n",
    "testing_accuracy_score = score(w, b, X_test, y_test)\n",
    "print(training_accuracy_score)\n",
    "print(testing_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version2</em> perceptron on the <em>training</em> data?</u></font></P>\n",
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version2</em> perceptron on the <em>testing</em> data?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy (version 2): 78%\n",
    "Testing accuracy (version 2): 79.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>perceptron_train_version3</code> that trains a perceptron but this time, unlike version 2 above, the function should shuffle the data at the start of each epoch. The function should take as input an array <code>X</code> of feature vectors and an array <code>y</code> of labels. It should implement the perceptron training algorithm which learns a weight vector <code>w</code> <em>and</em> a bias term <code>b</code>. The number of epochs should be 20. The function should shuffle the data at the start of each epoch. The function should return two elements, the learned weight vector <code>w</code> and the learned bias term <code>b</code>.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The perceptron_train_version3 function takes an array X of feature vectors and an array y of labels as input.\n",
    "# The function trains a perceptron. The number of epochs should be 20.\n",
    "# The data is shuffled at the start of each epoch.\n",
    "# The function returns the weight vector w and the bias term b that it learns.\n",
    "\n",
    "def perceptron_train_version3(X, y):\n",
    "    b = 0\n",
    "    w = np.zeros(X.shape[1])\n",
    "    epochs = 20\n",
    "    while(epochs > 0):\n",
    "        X,y = shuffle(X,y)\n",
    "        counter = 0 \n",
    "        for i in range(len(X[:, 0])):\n",
    "            if (y[i]*(np.dot(w,X[i])+b))<=0:\n",
    "                w = w + y[i]* X[i]\n",
    "                b = b + y[i]\n",
    "                counter += 1\n",
    "        if counter==0:\n",
    "            epochs=0\n",
    "        epochs -= 1\n",
    "    return w,b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Use your <code>perceptron_train_version3</code> function to train a perceptron on the <em>training</em> data. Then use the <code>score</code> function to assess the accuracy of the perceptron first on the <em>training</em> data and second on the <em>testing</em> data.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7851123595505618\n",
      "0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "# Assess the accuracy of your perceptron (version 3) on the training data and on the testing data\n",
    "\n",
    "w,b = perceptron_train_version3(X_train, y_train)\n",
    "training_accuracy_score = score(w, b, X_train, y_train)\n",
    "testing_accuracy_score = score(w, b, X_test, y_test)\n",
    "print(training_accuracy_score)\n",
    "print(testing_accuracy_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version3</em> perceptron on the <em>training</em> data?</u></font></P>\n",
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version3</em> perceptron on the <em>testing</em> data?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy (version 3): 78.51%\n",
    "Testing accuracy (version 3): 80.45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write a function <code>perceptron_train_version4</code> that trains a perceptron but this time, unlike version 3 above, rather than return the final weight vector and bias term, the function will compute an <em>averaged</em> perceptron and return the average weight vector and the average bias term. The function should take as input an array <code>X</code> of feature vectors and an array <code>y</code> of labels. It should implement the <em>averaged</em> perceptron training algorithm which keeps track of the average weight vector and bias term, where the average is over all intermediary weight vectors and bias terms that it computes throughout its learning. The number of epochs should be 20. The function should shuffle the data at the start of each epoch. The function should return two elements, the average weight vector and the average bias term.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The perceptron_train_version4 function takes an array X of feature vectors and an array y of labels as input.\n",
    "# The function trains a perceptron. The number of epochs should be 20.\n",
    "# The data is shuffled at the start of each epoch.\n",
    "# The function implements the *averaged* perceptron learning algorithm.\n",
    "# The function returns the *average* weight vector w and the *average* bias term b that it learns.\n",
    "\n",
    "def perceptron_train_version4(X, y):\n",
    "    b = 0\n",
    "    w = np.zeros(X.shape[1])\n",
    "    w_a = np.zeros(X.shape[1])\n",
    "    b_a = 0\n",
    "    epochs = 20\n",
    "    single_epoch = 20\n",
    "    while(epochs>0):\n",
    "        X,y = shuffle(X,y)\n",
    "        counter = 0 \n",
    "        for i in range(len(X[:, 0])):\n",
    "            if (y[i]*(np.dot(w,X[i])+ b))<=0:\n",
    "                w = w + y[i]*X[i]\n",
    "                b = b + y[i]\n",
    "                counter += 1\n",
    "        if counter==0:\n",
    "            break\n",
    "        w_a+=w\n",
    "        b_a+=b\n",
    "        epochs -= 1\n",
    "    w_a=w_a/(len(X[:, 0])*(single_epoch-epochs)) \n",
    "    b_a=b_a/(len(X[:, 0])*(single_epoch-epochs))\n",
    "    return w_a,b_a\n",
    "                    \n",
    "w_a, b_a = perceptron_train_version4(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Use your <code>perceptron_train_version4</code> function to train a perceptron on the <em>training</em> data. Then use the <code>score</code> function to assess the accuracy of the perceptron first on the <em>training</em> data and second on the <em>testing</em> data.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9033333333333333\n",
      "0.945\n"
     ]
    }
   ],
   "source": [
    "# Assess the accuracy of your perceptron (version 4) on the training data and on the testing data\n",
    "w,b = perceptron_train_version4(X_train, y_train)\n",
    "training_accuracy_score = score(w, b, X_train, y_train)\n",
    "testing_accuracy_score = score(w, b, X_test, y_test)\n",
    "print(training_accuracy_score)\n",
    "print(testing_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version4</em> perceptron on the <em>training</em> data?</u></font></P>\n",
    "<P><font color=\"maroon\"><u>What is the accuracy of your <em>version4</em> perceptron on the <em>testing</em> data?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy (version 4): 90.33%\n",
    "Testing accuracy (version 4): 94.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Please answer the following question that relates to the relative performance of the perceptron when trained using version 1, version 2, version 3, and version 4:</P>\n",
    "<P><font color=\"maroon\"><u>Which perceptron training advancement led to the biggest increase in accuracy on the <em>testing</em> data: updating the bias term, shuffling the data at the start of each epoch, using the average weight vector and bias term?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score on the testing data was for version 4. Version 4 used average weight vector and  bias term. (As well as utilizing shiuffling the data and updating the bias term) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Throughout this task, you should not have used the <code>sklearn</code> library at all. For this final part, you should now use the <code>sklearn</code> library. Create an <code>sklearn</code> Perceptron setting the number of epochs to be 20 and the random_state to be 0. Train the perceptron on the <em>training</em> data and assess its accuracy on both the <em>training</em> data and the <em>testing</em> data.</P> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.87\n"
     ]
    }
   ],
   "source": [
    "# Create an sklearn Perceptron with the number of epochs set to 20 and the random_state set to 0.\n",
    "# Train the perceptron and assess its accuracy on both the training data and the testing data.\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "perceptrons = linear_model.Perceptron(max_iter=20)\n",
    "perceptrons.fit(X_train, y_train)\n",
    "\n",
    "training_accuracy_score = perceptrons.score(X_test, y_test)\n",
    "testing_accuracy_score = perceptrons.score(X_train, y_train)\n",
    "print(training_accuracy_score)\n",
    "print(testing_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the accuracy of the <code>sklearn</code> perceptron on the <em>training</em> data?</u></font></P>\n",
    "<P><font color=\"maroon\"><u>What is the accuracy of the <code>sklearn</code> perceptron on the <em>testing</em> data?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy (sklearn version): 90%\n",
    "Testing accuracy (sklearn version): 87% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>How does the accuracy of your averaged perceptron (version 4) compare with that of <code>sklearn</code>'s perceptron?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for version 4 of perceptron training is a lot higher than the sklearn's perceptron training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Submitting your work\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate your name and the names of any partner that worked with you on this project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Zeynep Yalcin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate anyone else that you collaborated with in the process of doing the project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborators: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, approximately how many hours did you spend on each of (1) Task 1, (2) Task 2, (3) Task 3, and (4) Total?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hours on Task 1: 30 minutres\n",
    "Hours on Task 2: 3 hours\n",
    "Hours on Task 3: 5 hours \n",
    "Total hours: 8.5 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, did you abide by the <a href=\"https://www.wellesley.edu/studentlife/aboutus/honor\">Honor Code</a> and is all of the work that you are submitting your own and/or your partner's?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abide by Honor Code: Zeynep Yalcin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>To submit this project, please upload your <code>Project2.ipynb</code> file to the <code>Project2</code> folder that the instructor created and shared with you in your Google drive.</u></font></P>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
