{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><center>Project 4<BR><BR>\n",
    "Recommender Systems</center></H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 1: Algorithmic Bias\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Read <a href=\"https://cacm.acm.org/magazines/2016/10/207759-battling-algorithmic-bias/abstract\">this article</a> (also available <a href=\"https://drive.google.com/file/d/1bRKH--BoCAQw7ZyK8xmBGGZR2lyPlRaN/view?usp=sharing\">here</a>) about bias in algorithms.</P>\n",
    "\n",
    "<P>Please address (minimum 200 words) the following questions in the space below. As the article describes, \"common wisdom among programmers is to develop a pure algorithm that does not incorporate protected attributes into the model,\" where protected classes may include aspects such as race, gender, age, sexual orientation, and disability status. As a result, the algorithms can be bias. How might algorithms be evaluated for bias? Are there machine learning applications where you would sacrifice accuracy in order to reduce bias? Are there machine learning applications where you would allow bias in order to increase accuracy?</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of themost important thing a programmer can do is to work to reduce bias. If humans have bias and it inherently affects our dicision making and we have a way of mitigating that bias within our algoirthms which we also use for decision making, that should be our prioity. Obviously there is a line between compriamising the accuracy of the model in order to make it less biased, but overall I do think reducing bias is more important and if the accuracy decreases a little bit in my opinion that is fine. I have actually taught a course on the Northpointe algorithm and it has terrible rates of false identification for Black people, and it is impossible for computer scientists to be able to fix the issue because it is a black box algorithm. I think one of the most obvious solutions to making sure an algorithm can be evaluated for bias is training it for different data sets. One data set might include more diversely ranging data while the other could be more narrow, and depending on how the algorithm performs on the two different sets of data, some idea of how biased the algorithm is could be gathered. Other ways to measure bias could include seeing how data sets for minorities compare to the majority and seeing if the algorithm results in different predictions. I absolutely think there would be machine learning models where I would sacrifice accuracy to reduce bias. Northopinte being a prime example of this. I think it is more important to make sure populations that are already harmed by systems in place be protected my algoirthms whenever possible. I can't think of machine learning applications where I wouldn't want to reduce bias, maybe if the data was related to a biological, mathematical or checmical study then sure. But if the data concerns human lives and well-being I think reducing bias is of the utmost importance. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 2: Pipeline for Classification\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>As broader context for this project, little or no starter code is provided for the tasks in the project. One of the goals of this lack of starter code is to give you an opportunity to practice developing meaningful computational artifacts mostly or entirely from scratch.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>To start, let's make a simple pipeline that integrates in one function some of the aspects of supervised classification.</P>\n",
    "\n",
    "<P>Create a function named <code>pipeline</code> that takes three arguments:</P>\n",
    "<ol>\n",
    "    <li>The name of a comma separated values (CSV) file. Assume the file has a header row and all subsequent rows contain numerical data. The last column in the file corresponds to classification labels.</li>\n",
    "    <li>A Boolean indicating whether feature scaling should be performed on the data in the file.</li>\n",
    "    <li>A supervised classification model, such as a random forest classifier, a <em>k</em> nearest neighbors classifier, a logistic regression classifier, or a support vector machine.</li>\n",
    "</ol>\n",
    "\n",
    "<P>Your <code>pipeline</code> function should:</P>\n",
    "<ol>\n",
    "    <li>read in the specified file</li>\n",
    "    <li>extract the feature vectors (e.g., <em>X</em>) and labels (e.g., <em>y</em>)</li>\n",
    "    <li>split the data into training (80%) and testing (20%) (with <code>random_state=0</code>)</li>\n",
    "    <li>perform feature scaling <em>if</em> the specified Boolean argument is <code>True</code></li>\n",
    "    <li>train the classification model on the training data</li>\n",
    "    <li>print out the accuracy of the classification model on the testing data</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The *pipeline* function executes some of the aspects of supervised\n",
    "# classification on a set of data.\n",
    "# The function takes three arguments: the name of a CSV file with a header line and\n",
    "# whose last column contains labels, a Boolean indicating if feature scaling\n",
    "# should be performed on the data in the file, and a supervised classification model.\n",
    "# The function reads in data from the file, splits the data into training (80%)\n",
    "# and testing (20%), performs feature scaling if specified by the Boolean argument,\n",
    "# trains the model, and prints out the model's accuracy on the testing data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(csv_file, feature_scaling, classification):\n",
    "    DATA = np.loadtxt(csv_file, delimiter=',', skiprows=1)  # Read data from comma delimited file\n",
    "    X = DATA[:, :-1]\n",
    "    y = DATA[:, -1] # get the last column of the rows (should be 0 or 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit(X_train, y_train)\n",
    "    X_train_scaled_transform = scaler.transform(X_train)\n",
    "    X_test_transform = scaler.transform(X_test)\n",
    "    if feature_scaling == True and classification == 'knn': \n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train_scaled_transform, y_train)\n",
    "        y_pred= knn.predict(X_test_transform)\n",
    "        pscore = precision_score(y_test, y_pred)\n",
    "        return(pscore)\n",
    "    elif feature_scaling == True and classification == 'logistic':\n",
    "        logistic = LogisticRegression(random_state=0)\n",
    "        logistic.fit(X_train_scaled_transform, y_train)\n",
    "        y_pred= logistic.predict(X_test_transform)\n",
    "        pscore = precision_score(y_test, y_pred)\n",
    "        return(pscore)\n",
    "    elif feature_scaling == True and classification == 'random_forest':\n",
    "        random_forest = RandomForestClassifier(random_state=0)\n",
    "        random_forest.fit(X_train_scaled_transform, y_train)\n",
    "        y_pred= random_forest.predict(X_test_transform)\n",
    "        pscore = precision_score(y_test, y_pred)\n",
    "        return(pscore)\n",
    "    elif feature_scaling == True and classification == 'svm':\n",
    "        svc = SVC(random_state= 0)\n",
    "        svc.fit(X_train_scaled_transform, y_train)\n",
    "        y_pred= svc.predict(X_test_transform)\n",
    "        pscore = precision_score(y_test, y_pred)\n",
    "        return(pscore)\n",
    "    elif feature_scaling == False and classification == 'logistic':\n",
    "        logistic = LogisticRegression(random_state=0)\n",
    "        logistic.fit(X_train, y_train)\n",
    "        test_score = logistic.score(X_test, y_test)\n",
    "        return(test_score)\n",
    "    elif feature_scaling == False and classification == 'random_forest':\n",
    "        random_forest = RandomForestClassifier(random_state=0)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        test_score = random_forest.score(X_test, y_test)\n",
    "        return(test_score)\n",
    "    elif feature_scaling == False and classification == 'knn':    \n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train, y_train)\n",
    "        test_score = knn.score(X_test, y_test)\n",
    "        return(test_score)\n",
    "    elif feature_scaling == False and classification == 'svm':    \n",
    "        svc = SVC(random_state= 0)\n",
    "        svc.fit(X_train, y_train)\n",
    "        test_score = svc.score(X_test, y_test)\n",
    "        return(test_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('admission.csv', False, 'random_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>With the <code>pipeline</code> function above, you have a mechanism for quickly invoking several aspects of supervised classification. Below, you should experiment with executing your <code>pipeline</code> function on the following four datasets:</P>\n",
    "<ol>\n",
    "    <li>The file <code>admission.csv</code> contains GPA and GMAT score data on people who have/haven't been <a href=\"https://www.kaggle.com/willianleite/mba-admission\">admitted to an MBA program</a> (graduate school in business). How well can you predict who will be admitted based on their GPA and their GMAT standardized test score?</li>\n",
    "    <li>The file <code>dementia.csv</code> contains MRI scans and other health data on people who do/don't have <a href=\"https://www.kaggle.com/shashwatwork/dementia-prediction-dataset\">dementia</a>. How well can you predict who has dementia based on this health data?</li>\n",
    "    <li>The file <code>star.csv</code> contains chromaticity and spectral data for different stars in the galaxy. In this <a href=\"https://www.kaggle.com/vinesmsuic/star-categorization-giants-and-dwarfs\">stellar classification problem</a>, how well can you determine which stars are \"giants\" and which are \"dwarfs\".</li>\n",
    "    <li>The file <code>airlineDelays.csv</code> contains data on airplane flights and whether or not the flight was delayed. Data include information on the airline, the departing airport of the flight, the weather, the number of seats on the flight, the number of flight attendants, the age of the plane, etc. How well can you predict <a href=\"https://www.kaggle.com/threnjen/2019-airline-delays-and-cancellations\">flight delays</a>?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9722222222222222\n",
      "0.8528557599225557\n",
      "0.6253902185223725\n"
     ]
    }
   ],
   "source": [
    "# Experiments executing *pipeline* on four different data sets\n",
    "\n",
    "print(pipeline('admission.csv', False, 'random_forest'))\n",
    "print(pipeline('dementia.csv', True, 'svm'))\n",
    "print(pipeline('star.csv', True, 'knn'))\n",
    "print(pipeline('airlineDelays.csv', True, 'logistic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For the <code>admission</code> data, what is the testing accuracy <code>without</code> feature scaling and using a <code>Random Forest</code> classifier (with <code>random_state=0</code>)?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For the <code>dementia</code> data, what is the testing accuracy <code>with</code> feature scaling and using a <code>Support Vector Machine</code> (with <code>random_state=0</code>)?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For the <code>star</code> data, what is the testing accuracy <code>with</code> feature scaling and using a <code><em>k</em> Nearest Neighbors</code> classifier?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "85.29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For the <code>airline delays</code> data, what is the testing accuracy <code>with</code> feature scaling and using a <code>Logistic Regression</code> classifier (with <code>random_state=0</code>)?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "62.54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 3: Sentiment Analysis of Movie Reviews\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Remember in Exercise 3 where you performed sentiment analysis of Twitter data? If not, reviewing it will be very helpful here :). Here you will perform sentiment analysis of <a href=\"https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\">movie reviews</a>, i.e., you will determine whether a movie review is negative or positive based on the text of the review.</P>\n",
    "<P>The file <code>movie_reviews.txt</code> contains 50,000 lines. Each line contains a review of a movie followed by a label, either \"@@@negative\" or \"@@@positive\", indicating if the review is negative or positive. Your task is to:</P>\n",
    "<ol>\n",
    "    <li>read in the data from the file</li>\n",
    "    <li>randomly shuffle the data, while making sure each label stays with its corresponding review</li>\n",
    "    <li>store the data as a corpus and as labels</li>\n",
    "    <li>split the data into training (80%) and testing (20%)</li>\n",
    "    <li>use the Bag of Words approach (tf-idf) to vectorize the data (you should use unigrams rather than bigrams here)</li>\n",
    "    <li>use a logistic regression classifier to predict the sentiment of reviews</li>\n",
    "    <li>based on the logistic regression model weights, determine the 10 lowest weighted words (indicative of negative sentiment reviews) and the 10 highest weighted words (indicative of positive sentiment reviews)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in movie review data from file.\n",
    "# Randomly shuffle data, making sure each label stays with its corresponding review.\n",
    "# Store data as corpus and labels.\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "def readFile(filename):\n",
    "    DATA = []\n",
    "    in_file = open(filename, 'r')\n",
    "    line = in_file.readline()  # Ignore header line\n",
    "    line = in_file.readline()\n",
    "    while (line != ''):\n",
    "        try: \n",
    "            if (line.strip() == ''): \n",
    "                line = in_file.readline()\n",
    "                continue\n",
    "            firstCommaIndex = line.rfind('@@@')\n",
    "            label = line[(firstCommaIndex+3):]\n",
    "            review = line[:(firstCommaIndex)]\n",
    "            DATA.append([review, label])\n",
    "            line = in_file.readline()\n",
    "        except (UnicodeDecodeError, ValueError): line = ' '\n",
    "    in_file.close()\n",
    "    random.shuffle(DATA)  # Shuffle\n",
    "    return [row[0] for row in DATA], [row[1] for row in DATA]\n",
    "\n",
    "corpus, labels = readFile('movie_reviews.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999\n",
      "39999\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Separate into training and testing data\n",
    "\n",
    "TEST_SIZE = 0.2  # 20% testing data and 80% training data\n",
    "\n",
    "separator = int((1.0 - TEST_SIZE)*len(corpus))\n",
    "corpus_train = corpus[:separator]\n",
    "labels_train = labels[:separator]\n",
    "corpus_test = corpus[separator:]\n",
    "labels_test = labels[separator:]\n",
    "print(len(corpus_train))\n",
    "print(len(labels_train))\n",
    "print(len(corpus_test))\n",
    "print(len(labels_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39999, 92886)\n",
      "(39999,)\n"
     ]
    }
   ],
   "source": [
    "# Text feature extraction (using Bag of Words approach with unigrams) for training data\n",
    "\n",
    "# Text feature extraction for training data\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  # Use individual words as tokens\n",
    "X_train = vectorizer.fit_transform(corpus_train)\n",
    "y_train = np.array(labels_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 92886)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Text feature extraction (using Bag of Words approach with unigrams) for testing data\n",
    "\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "y_test = np.array(labels_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynoyalcin/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression to predict sentiment of reviews (with random_state=0)\n",
    "\n",
    "logistic = LogisticRegression(random_state=0)\n",
    "logistic.fit(X_train, y_train)\n",
    "test_score = logistic.score(X_test, y_test)\n",
    "print(test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lowest weighted words (indicative of negative sentiment tweets)\n",
      "worst\n",
      "bad\n",
      "awful\n",
      "waste\n",
      "boring\n",
      "terrible\n",
      "poor\n",
      "nothing\n",
      "worse\n",
      "horrible\n",
      "dull\n",
      "poorly\n",
      "stupid\n",
      "minutes\n",
      "fails\n",
      "disappointing\n",
      "annoying\n",
      "disappointment\n",
      "unfortunately\n",
      "supposed\n",
      "no\n",
      "lame\n",
      "script\n",
      "ridiculous\n",
      "save\n",
      "\n",
      "Highest weighted words (indicative of positive sentiment tweets)\n",
      "great\n",
      "excellent\n",
      "best\n",
      "perfect\n",
      "amazing\n",
      "wonderful\n",
      "loved\n",
      "enjoyed\n",
      "brilliant\n",
      "today\n",
      "favorite\n",
      "hilarious\n",
      "fun\n",
      "well\n",
      "definitely\n",
      "love\n",
      "enjoyable\n",
      "highly\n",
      "superb\n",
      "it\n",
      "fantastic\n",
      "entertaining\n",
      "surprised\n",
      "still\n",
      "dvd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynoyalcin/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Get Logistic Regression weights\n",
    "learner = LogisticRegression(random_state=0)\n",
    "learner.fit(X_train, y_train)\n",
    "weights = learner.coef_  # Get the learned Perceptron weights\n",
    "sorted_weights = np.argsort(weights)  # Sort\n",
    "features = vectorizer.get_feature_names()  # Get the features\n",
    "print('\\nLowest weighted words (indicative of negative sentiment tweets)')\n",
    "for i in range(25): print(features[sorted_weights[0,i]])\n",
    "print('\\nHighest weighted words (indicative of positive sentiment tweets)')\n",
    "for i in range(25): print(features[sorted_weights[0,len(sorted_weights[0])-i-1]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the testing accuracy of your logistic regression model at determining the sentiment of movie reviews?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "89.8% accurate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For your logistic regression classifier, what are the 10 lowest weighted words, indicative of negative reviews?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worst,\n",
    "bad,\n",
    "awful,\n",
    "waste,\n",
    "boring,\n",
    "terrible,\n",
    "poor,\n",
    "nothing, \n",
    "worse,\n",
    "horrible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>For your logistic regression classifier, what are the 10 highest weighted words, indicative of positive reviews?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great,\n",
    "excellent,\n",
    "best,\n",
    "perfect,\n",
    "amazing,\n",
    "wonderful,\n",
    "loved,\n",
    "enjoyed,\n",
    "brilliant,\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 4: Detecting Fake News\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Can you use machine learning to distinguish <a href=\"https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\">fake news stories from true news stories</a>? You are provided two files, each containing over 20,000 lines, where each line corresponds to a news story. The file <code>Fake_News.txt</code> contains fake news stories. The file <code>True_News.txt</code> contains true news stories. Using the Bag of Words (tf-idf) approach, your task is to distinguish fake news stories from true news stories. We are not providing much guidance here (and no starter code) so that you can think about how best to tackle this problem largely from scratch.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "def readFile(filename, filename1):\n",
    "    DATA = []\n",
    "    in_file = open(filename, 'r')\n",
    "    in_file1 = open(filename1, 'r')\n",
    "\n",
    "    line = in_file.readline()  # Ignore header line\n",
    "    line1 = in_file1.readline()\n",
    "    while (line != ''):\n",
    "        try: \n",
    "            if (line.strip() == ''): \n",
    "                line = in_file.readline()\n",
    "                continue\n",
    "            firstCommaIndex = line.rfind('/n')\n",
    "            label = 0\n",
    "            news = line[:(firstCommaIndex)]\n",
    "            DATA.append([news, label])\n",
    "            line = in_file.readline()\n",
    "            if (line1.strip() == ''): \n",
    "                line1 = in_file1.readline()\n",
    "                continue\n",
    "            firstCommaIndex = line1.rfind('/n')\n",
    "            label = 1 \n",
    "            news = line1[:(firstCommaIndex)]\n",
    "            DATA.append([news, label])\n",
    "            line1 = in_file1.readline()\n",
    "        except (UnicodeDecodeError, ValueError): line = ' '\n",
    "    in_file.close()\n",
    "    in_file1.close()\n",
    "    random.shuffle(DATA)  # Shuffle\n",
    "    return [row[0] for row in DATA], [row[1] for row in DATA]\n",
    "\n",
    "corpus, labels = readFile('Fake_News.txt', 'True_News.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35405\n",
      "35405\n",
      "8852\n",
      "8852\n"
     ]
    }
   ],
   "source": [
    "# Your code here. \n",
    "# Rather than put all your code in this one cell, create multiple new cells as needed.\n",
    "\n",
    "TEST_SIZE = 0.2  # 20% testing data and 80% training data\n",
    "\n",
    "separator = int((1.0 - TEST_SIZE)*len(corpus))\n",
    "corpus_train = corpus[:separator]\n",
    "labels_train = labels[:separator]\n",
    "corpus_test = corpus[separator:]\n",
    "labels_test = labels[separator:]\n",
    "print(len(corpus_train))\n",
    "print(len(labels_train))\n",
    "print(len(corpus_test))\n",
    "print(len(labels_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35405, 110408)\n",
      "(35405,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  # Use individual words as tokens\n",
    "X_train = vectorizer.fit_transform(corpus_train)\n",
    "y_train = np.array(labels_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8852, 110408)\n",
      "(8852,)\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(corpus_test)\n",
    "y_test = np.array(labels_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783099864437416\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(random_state=0)\n",
    "logistic.fit(X_train, y_train)\n",
    "test_score = logistic.score(X_test, y_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lowest weighted words (indicative of Fake news)\n",
      "via\n",
      "this\n",
      "us\n",
      "read\n",
      "com\n",
      "just\n",
      "gop\n",
      "that\n",
      "image\n",
      "mr\n",
      "featured\n",
      "is\n",
      "hillary\n",
      "you\n",
      "watch\n",
      "obama\n",
      "pic\n",
      "america\n",
      "here\n",
      "https\n",
      "sen\n",
      "even\n",
      "these\n",
      "getty\n",
      "rep\n",
      "\n",
      "Highest weighted words (indicative of True news)\n",
      "said\n",
      "on\n",
      "in\n",
      "republican\n",
      "told\n",
      "presidential\n",
      "minister\n",
      "reporters\n",
      "had\n",
      "nov\n",
      "democratic\n",
      "spokesman\n",
      "edt\n",
      "monday\n",
      "comment\n",
      "its\n",
      "representatives\n",
      "statement\n",
      "saying\n",
      "government\n",
      "london\n",
      "election\n",
      "united\n",
      "senate\n",
      "ly\n"
     ]
    }
   ],
   "source": [
    "learner = LogisticRegression(random_state=0)\n",
    "learner.fit(X_train, y_train)\n",
    "weights = learner.coef_  # Get the learned Perceptron weights\n",
    "sorted_weights = np.argsort(weights)  # Sort\n",
    "features = vectorizer.get_feature_names()  # Get the features\n",
    "print('\\nLowest weighted words (indicative of Fake news)')\n",
    "for i in range(25): print(features[sorted_weights[0,i]])\n",
    "print('\\nHighest weighted words (indicative of True news)')\n",
    "for i in range(25): print(features[sorted_weights[0,len(sorted_weights[0])-i-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What is the testing accuracy of your machine learning method in determining whether a news story is fake?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97.8% accurate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What are 10 words highly associated with true news stories?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "said,\n",
    "on,\n",
    "in,\n",
    "republican,\n",
    "told,\n",
    "presidential,\n",
    "minister,\n",
    "reporters,\n",
    "had,\n",
    "nov,\n",
    "democratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>What are 10 words highly associated with fake news stories?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "via,\n",
    "this,\n",
    "us,\n",
    "read,\n",
    "com,\n",
    "just,\n",
    "gop,\n",
    "that,\n",
    "image,\n",
    "mr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 5: Collaborative Filtering\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>In this task, you will use collaborative filtering to predict how a person might rate a business. Ratings are numbers between 1 and 5 corresponding, for example, to how many stars a person gives the business in a review. The data come from <a href=\"https://www.yelp.com/dataset\">Yelp</a>.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>To begin, read in the <code>training.csv</code> file containing <em>training</em> data. Unlike many other <code>CSV</code> files that we have worked with previously, the data are not in matrix form (rows and columns) here, but rather a list. Each line in the file contains three comma delimited values: the first corresponds to the ID of a person (user), the second correspond to the ID of a business (item), and the third corresponds to the rating (1 through 5) that the person gave the business in a review. The file contains over 80,000 lines, i.e., over 80,000 ratings that people gave to businesses. Write code below to create a user-item matrix, as described in class, from the data in the file. For each line in the file, you can think of the user (person) ID as indicating the row in the user-item matrix, the item (business) ID as indicating the column in the user-item matrix, and the rating as the value to be inserted in the user-item matrix at the specified row and column. Note that your user-item matrix will have many more than 80,000 entries even though the data contain only ~80,000 ratings. Thus, the matrix will be sparse, i.e., most values in the matrix should correspond to zero since each person rates only a small subset of all businesses.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4207</th>\n",
       "      <th>4208</th>\n",
       "      <th>4209</th>\n",
       "      <th>4210</th>\n",
       "      <th>4211</th>\n",
       "      <th>4212</th>\n",
       "      <th>4213</th>\n",
       "      <th>4214</th>\n",
       "      <th>4215</th>\n",
       "      <th>4216</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 4217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item  0     1     2     3     4     5     6     7     8     9     ...  4207  \\\n",
       "user                                                              ...         \n",
       "0      4.0   4.0   2.0   4.0   2.0   5.0   NaN   NaN   5.0   2.0  ...   NaN   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "3      NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "913    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "914    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "915    5.0   3.0   3.0   NaN   NaN   5.0   1.0   NaN   NaN   5.0  ...   NaN   \n",
       "916    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "917    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "item  4208  4209  4210  4211  4212  4213  4214  4215  4216  \n",
       "user                                                        \n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "913    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "914    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "915    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "916    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "917    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[918 rows x 4217 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in training data and create user-item matrix\n",
    "\n",
    "df = pd.read_csv('training.csv', header=None)\n",
    "rows = df[0]\n",
    "cols = df[1]\n",
    "ratings = df[2]\n",
    "df.columns = ['user','item','rating']\n",
    "df1 = df.pivot(index='user', columns='item', values='rating')\n",
    "\n",
    "df1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Ultimately, our goal is to use filled-in (i.e., non-zero) values in the user-item matrix to predict empty (i.e., zero) values in the user-item matrix. In other words, we want to predict how a person might rate a business, based on how a person has rated other businesses or how a business has been rated by other people. Collaborative filtering.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>Below, write a function named <code>prediction</code> that predicts a value (i.e., rating) for a given location (row index and column index) in the user-item matrix. Your prediction algorithm should proceed as follows:<BR>\n",
    "<UL>\n",
    "<li>Determine all rows in the matrix that contain non-zero values in the specified column. This will give us information on all people that rated the business of interest.</li>\n",
    "<li>Using the <code>sklearn</code> unsupervised <code><a href=\"http://scikit-learn.org/stable/modules/neighbors.html\">NearestNeighbors</a></code> algorithm, for the specified row in the user-item matrix, compute the <em>k</em> nearest neighbors among the rows that contain non-zero values in the specified column. This will give us the <em>k</em> most similar people that rated the business of interest. You should use the <code>cosine</code> metric in the <code>NearestNeighbors</code> algorithm for computing distance between rows in a matrix. If there are fewer than <em>k</em> people who have rated the business, you can use everyone who rated the business rather than the <em>k</em> most similar people (since there aren't <em>k</em> such people).</li>\n",
    "<li>For the <em>k</em> nearest neighbors of the specified row, compute and return the mean value for the specified column. This will give us the average rating of the business from the <em>k</em> most similar people to the person of interest. In other words, we are predicting how someone will rate a business based on the ratings of similar people who have already rated the business.</li>\n",
    "</UL><BR>\n",
    "Your <code>prediction</code> function should have at least four inputs: your user-item matrix, a paramter <em>k</em>, a specified row, and a specified column (as well as any other input parameters that you deem helpful). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The *prediction* function takes in four (or more) parameters corresponding to\n",
    "# the user-item matrix, k, the row (person) index, and the column (business) index.\n",
    "# The function returns the average (mean) rating of a business from the k most\n",
    "# similar people to the specified person.\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def prediction(matrix, k, row, column):\n",
    "    item = matrix[:][column] \n",
    "    xrow = matrix.iloc[row].fillna(0)\n",
    "    xrow = xrow.to_numpy()\n",
    "    item_row = np.argwhere(item.notnull().values).tolist()\n",
    "    user_row = [] \n",
    "    for item in item_row:\n",
    "        for i in item:\n",
    "            user_row.append(i)\n",
    "    df2 = matrix.iloc[user_row]\n",
    "    df2 = df2.fillna(0)\n",
    "    if df2.shape[0] >= k:\n",
    "        model = NearestNeighbors(metric='cosine', n_neighbors=k).fit(df2)\n",
    "    if df2.shape[0] < k:\n",
    "        model = NearestNeighbors(metric='cosine', n_neighbors=df2.shape[0]).fit(df2)\n",
    "    dist, indices = model.kneighbors(xrow.reshape(1,-1))\n",
    "    averages = []\n",
    "    for row in indices[0]:\n",
    "        averages.append(df2.iloc[row][column])\n",
    "    mean = np.mean(averages)\n",
    "    return(mean)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Let's evaluate how well we do at predicting people's ratings of businesses. The file <code>testing.csv</code> contains approximately 4,000 ratings that different people have given to different businesses. These <em>testing</em> ratings correspond to ~4,000 entries in the user-item matrix that contain zero values. So we can use the user-item matrix (our <em>training</em> data) to predict ratings in these ~4,000 cases and compare our predictions to the actual rating found in the <em>testing</em> data in order to see how accurate our predicted ratings are.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code below that reads in <em>testing</em> data from <code>testing.csv</code>. Each line in the file contains three comma delimited values: the first corresponds to the ID of a person (user), the second correspond to the ID of a business (item), and the third corresponds to the rating (1 through 5) that the person gave the business in a review. For each line, use the <code>prediction</code> function that you wrote above to predict the rating that the specified user might give the specified business. Keep track of this predicted rating as well as the actual rating from the <em>testing</em> data. After processing all lines in the <em>testing</em> file, you should have ~4,000 predicted ratings and the same number of actual ratings. To compare how far our predictions are from the actual ratings, we'll compute the root mean-squared error (RMSE) between the two, e.g., by computing the square root of the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\">mean-squared error</a> (MSE). As a point of reference, the instructor found a RMSE a bit under 1.0 depending on the value of <em>k</em> used, i.e., the predicted ratings were a bit less than 1 \"star\" from the actual ratings on average. Try computing the RMSE on the <em>testing</em> data for each of the following eleven values for the parameter <em>k</em>: 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.1 3.5 3.9 ... 4.1 3.9 3.9]\n",
      "[5 3 4 ... 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Read in testing data and for each line in the file,\n",
    "# calculate the predicted rating of the specified person and business.\n",
    "# Compare the predicted ratings with the actual ratings in the testing data\n",
    "# by computing the root mean-squared error (RMSE).\n",
    "# Compute the RMSE for 11 different values of parameter k: 1,5,10,15,20,25,30,35,40,45,50\n",
    "\n",
    "df = pd.read_csv('testing.csv', header=None)\n",
    "df.columns = ['user','item','rating']\n",
    "results = df[['rating']]\n",
    "\n",
    "df = df.drop(columns=['rating'])\n",
    "df.head()\n",
    "ratings = np.zeros(df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    ratings[i] = prediction(df1,10,df.iloc[i][0],df.iloc[i][1])\n",
    "print(ratings) \n",
    "\n",
    "short_list = [] \n",
    "for item in results.values:\n",
    "    for i in item:\n",
    "        short_list.append(i)\n",
    "short_array = np.asarray(short_list)\n",
    "print(short_array)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743359918901499"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = short_array\n",
    "y_pred = ratings\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ratings_k = np.zeros((len(k),df.shape[0]))\n",
    "rmse = np.zeros(len(k))\n",
    "for z in range(len(k)):\n",
    "    for i in range(df.shape[0]):\n",
    "        ratings_k[z][i] = prediction(df1,k[z],df.iloc[i][0],df.iloc[i][1])\n",
    "    rmse[z] = mean_squared_error(y_true, ratings_k[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44915062, 0.94519466, 0.87433599, 0.86201803, 0.85863899,\n",
       "       0.85894258, 0.8591207 , 0.8597084 , 0.8596854 , 0.85918819,\n",
       "       0.86063692])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For which of the eleven values of <em>k</em> do you observe the smallest RMSE? What is the RMSE at this optimal value of <em>k</em>?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "the smallest RMSE value is 0.85863899, which is observed for the k value of 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>Above, you predicted how a user might rate a business by seeing how similar users rated the same business (and taking the average value of these similar users' ratings of the business). As an alternative method for predicting the rating a user might give to a business, we could look at similar <em>businesses</em> rather than similar <em>users</em>. In this alternative approach, we will take our user and find similar <em>businesses</em> that they have rated. Our predicted rating will be the mean value of the user's ratings of <em>k</em> similar businesses. Below, write code to compute the RMSE between predicted ratings and actual ratings using eleven different values for the parameter <em>k</em>: 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50. Predicted ratings should be determined by calculating, among businesses rated by a specified user, the average rating that the user gave to the <em>k</em> most similar businesses. <em>Hint: You needn't change your <code>prediction</code> function above. Changing a single line of code elsewhere may be sufficient.</em></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>908</th>\n",
       "      <th>909</th>\n",
       "      <th>910</th>\n",
       "      <th>911</th>\n",
       "      <th>912</th>\n",
       "      <th>913</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4217 rows × 918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user  0    1    2    3    4    5    6    7    8    9    ...  908  909  910  \\\n",
       "item                                                    ...                  \n",
       "0     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  5.0   \n",
       "2     2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  3.0   \n",
       "4     2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "4212  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4213  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4214  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4215  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4216  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "user  911  912  913  914  915  916  917  \n",
       "item                                     \n",
       "0     NaN  NaN  NaN  NaN  5.0  NaN  NaN  \n",
       "1     NaN  NaN  NaN  NaN  3.0  NaN  NaN  \n",
       "2     NaN  NaN  NaN  NaN  3.0  NaN  NaN  \n",
       "3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "4212  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4213  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4214  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4215  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4216  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[4217 rows x 918 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in testing data and for each line in the file,\n",
    "# calculate the predicted rating of the specified person and business.\n",
    "# Compare the predicted ratings with the actual ratings in the testing data\n",
    "# by computing the root mean-squared error (RMSE).\n",
    "# Compute the RMSE for 11 different values of parameter k: 1,5,10,15,20,25,30,35,40,45,50\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('training.csv', header=None)\n",
    "df2.columns = ['user','item','rating']\n",
    "df3 = df2.pivot(index='item', columns='user', values='rating')\n",
    "df3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>631</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867</td>\n",
       "      <td>3789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>430</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>62</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>625</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>384</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>603</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  item\n",
       "0      562   308\n",
       "1       58  1731\n",
       "2      281   427\n",
       "3      631   141\n",
       "4      867  3789\n",
       "...    ...   ...\n",
       "4410   430   334\n",
       "4411    62   260\n",
       "4412   625   758\n",
       "4413   384  1017\n",
       "4414   603  1174\n",
       "\n",
       "[4415 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('testing.csv', header=None)\n",
    "df4.columns = ['user','item','rating']\n",
    "df4.columns = ['user','item','rating']\n",
    "\n",
    "results1 = df4[['rating']]\n",
    "\n",
    "df4 = df4.drop(columns=['rating'])\n",
    "df4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9, 3.5, 3.7, ..., 2.9, 3.5, 3.5])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.zeros(df4.shape[0])\n",
    "for i in range(df4.shape[0]):\n",
    "    ratings[i] = prediction(df3,10,df4.iloc[i][1],df4.iloc[i][0])\n",
    "ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 4 ... 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "short_list1 = [] \n",
    "for item in results1.values:\n",
    "    for i in item:\n",
    "        short_list1.append(i)\n",
    "short_array1 = np.asarray(short_list1)\n",
    "print(short_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ratings_k1 = np.zeros((len(k1),df4.shape[0]))\n",
    "rmse1 = np.zeros(len(k1))\n",
    "for z in range(len(k1)):\n",
    "    for i in range(df4.shape[0]):\n",
    "        ratings_k1[z][i] = prediction(df3,k1[z],df4.iloc[i][1],df4.iloc[i][0])\n",
    "    rmse1[z] = mean_squared_error(short_array1, ratings_k1[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59479049, 0.95605889, 0.88927366, 0.86871762, 0.85748533,\n",
       "       0.85316512, 0.84970183, 0.84752743, 0.84711902, 0.84662163,\n",
       "       0.84849161])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For which of the eleven values of <em>k</em> do you observe the smallest RMSE? What is the RMSE at this optimal value of <em>k</em>?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The smallest RMSE value is 0.84662163 which is observed for k= 45. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For their optimal values of parameter <em>k</em>, which approach led to more accurate predictions: (1) among users that have rated a business, finding the average rating that the <em>k</em> most similar users gave the business or (2) among businesses rated by a user, finding the average rating that the user gave to the <em>k</em> most similar businesses?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The second approach led to more accurate predictions (smaller rmse values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Submitting your work\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate your name and the names of any partner that worked with you on this project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Zeynep Yalcin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate anyone else that you collaborated with in the process of doing the project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborators: went to TA office hours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, approximately how many hours did you spend on each of (1) Task 1, (2) Task 2, (3) Task 3, (4) Task 4, (5) Task 5, and (6) Total?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hours on Task 1: 30 minutes\n",
    "Hours on Task 2: 1 hour\n",
    "Hours on Task 3: 45 minutes \n",
    "Hours on Task 4: 1 hour\n",
    "Hours on Task 5: 7.15 hours \n",
    "Total hours: 10.5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, did you abide by the <a href=\"https://www.wellesley.edu/studentlife/aboutus/honor\">Honor Code</a> and is all of the work that you are submitting your own and/or your partner's?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abide by Honor Code: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>To submit this project, please upload your <code>Project4.ipynb</code> file to the <code>Project4</code> folder that the instructor created and shared with you in your Google drive.</u></font></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
